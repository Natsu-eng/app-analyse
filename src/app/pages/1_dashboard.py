import os
import streamlit as st
import pandas as pd
import time
import logging
import re
import psutil
import gc
import numpy as np
from functools import wraps
from typing import Dict, List, Any

from src.data.data_analysis import (
    compute_if_dask,
    is_dask_dataframe,
    auto_detect_column_types,
    detect_useless_columns,
    cleanup_memory
)
from src.evaluation.exploratory_plots import (
    plot_overview_metrics,
    plot_missing_values_overview,
    plot_cardinality_overview,
    plot_distribution,
    plot_bivariate_analysis,
    plot_correlation_heatmap
)

# Configuration du logging avec rotation
import logging.handlers
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.handlers.RotatingFileHandler('logs/dashboard.log', maxBytes=10*1024*1024, backupCount=5),
        logging.StreamHandler()
    ]
)

from src.shared.logging import get_logger
logger = get_logger(__name__)

# Configuration Streamlit pour la production
st.set_page_config(
    page_title="Dashboard Analytics", 
    page_icon="ðŸ“Š", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Constantes de configuration
class Config:
    MAX_PREVIEW_ROWS = 100
    MAX_SAMPLE_SIZE = 15000
    MAX_BIVARIATE_SAMPLE = 10000
    MEMORY_CHECK_INTERVAL = 180  # 3 minutes
    CACHE_TTL = 600  # 10 minutes
    TIMEOUT_THRESHOLD = 30
    MEMORY_WARNING = 85
    MEMORY_CRITICAL = 90

# Configuration production
def setup_production_environment():
    """Configuration optimisÃ©e pour l'environnement de production"""
    if 'production_setup_done' not in st.session_state:
        st.session_state.production_setup_done = True
        
        if os.getenv('STREAMLIT_ENV') == 'production':
            hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            .stDeployButton {display:none;}
            footer {visibility: hidden;}
            #stDecoration {display:none;}
            .stAlert > div {padding: 0.5rem;}
            .element-container {margin: 0.5rem 0;}
            </style>
            """
            st.markdown(hide_streamlit_style, unsafe_allow_html=True)

setup_production_environment()

# DÃ©corateur de monitoring avancÃ©
def monitor_performance(operation_name: str = ""):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                elapsed = time.time() - start_time
                
                if elapsed > 5:
                    logger.warning(f"SLOW: {operation_name or func.__name__} took {elapsed:.2f}s")
                
                return result
            except Exception as e:
                elapsed = time.time() - start_time
                logger.error(f"ERROR in {operation_name or func.__name__}: {str(e)} after {elapsed:.2f}s")
                raise
        return wrapper
    return decorator

st.title("ðŸ“Š Dashboard Exploratoire")

# Gestion d'Ã©tat centralisÃ©e et robuste
class StateManager:
    """Gestion centralisÃ©e de l'Ã©tat du dashboard"""
    
    REQUIRED_KEYS = {
        'column_types': (dict, type(None)),
        'rename_list': list,
        'columns_to_drop': list,
        'useless_candidates': list,
        'dataset_hash': (str, type(None)),
        'last_memory_check': (int, float),
        'dashboard_version': int,
        'selected_univar_col': (str, type(None)),
        'selected_bivar_col1': (str, type(None)),
        'selected_bivar_col2': (str, type(None))
    }
    
    @classmethod
    def initialize(cls):
        """Initialise l'Ã©tat avec validation"""
        defaults = {
            'column_types': None,
            'rename_list': [],
            'columns_to_drop': [],
            'useless_candidates': [],
            'dataset_hash': None,
            'last_memory_check': 0,
            'dashboard_version': 1,
            'selected_univar_col': None,
            'selected_bivar_col1': None,
            'selected_bivar_col2': None
        }
        
        for key, expected_type in cls.REQUIRED_KEYS.items():
            if key not in st.session_state:
                st.session_state[key] = defaults[key]
            elif not isinstance(st.session_state[key], expected_type):
                logger.warning(f"Invalid type for {key}, resetting")
                st.session_state[key] = defaults[key]
    
    @classmethod
    def reset_selections(cls):
        """Reset les sÃ©lections pour Ã©viter les erreurs"""
        selection_keys = ['selected_univar_col', 'selected_bivar_col1', 'selected_bivar_col2']
        for key in selection_keys:
            st.session_state[key] = None

StateManager.initialize()

# Monitoring systÃ¨me optimisÃ©
class SystemMonitor:
    """Monitoring systÃ¨me avec seuils configurables"""
    
    @classmethod
    @monitor_performance("system_check")
    def check_resources(cls):
        """VÃ©rifie les ressources systÃ¨me"""
        current_time = time.time()
        if current_time - st.session_state.last_memory_check > Config.MEMORY_CHECK_INTERVAL:
            try:
                memory_info = psutil.virtual_memory()
                memory_percent = memory_info.percent
                
                if memory_percent > Config.MEMORY_CRITICAL:
                    st.error(f"ðŸš¨ MÃ©moire critique: {memory_percent:.1f}%")
                    cls._emergency_cleanup()
                elif memory_percent > Config.MEMORY_WARNING:
                    st.warning(f"âš ï¸ MÃ©moire Ã©levÃ©e: {memory_percent:.1f}%")
                    cls._show_cleanup_option()
                
                st.session_state.last_memory_check = current_time
                
            except Exception as e:
                logger.error(f"System check failed: {e}")
    
    @staticmethod
    def _emergency_cleanup():
        """Nettoyage d'urgence"""
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ðŸ§¹ Nettoyer", type="primary", key="emergency_clean"):
                cleanup_memory()
                st.cache_data.clear()
                gc.collect()
                st.success("MÃ©moire nettoyÃ©e")
                st.rerun()
    
    @staticmethod
    def _show_cleanup_option():
        """Option de nettoyage standard"""
        col1, col2 = st.columns([4, 1])
        with col2:
            if st.button("ðŸ§¹", help="Nettoyer mÃ©moire", key="normal_clean"):
                cleanup_memory()
                st.success("âœ… NettoyÃ©")
                st.rerun()

SystemMonitor.check_resources()

# Validation des donnÃ©es
class DataValidator:
    """Validation et gestion des donnÃ©es"""
    
    @staticmethod
    @monitor_performance("validate_dataframe")
    def validate_dataframe() -> pd.DataFrame:
        """Valide le DataFrame avec gestion d'erreurs"""
        if 'df' not in st.session_state or st.session_state.df is None:
            st.error("ðŸ“Š Aucun dataset chargÃ©")
            st.info("Chargez un dataset depuis la page d'accueil pour commencer l'analyse.")
            if st.button("ðŸ  Retour Ã  l'accueil"):
                st.switch_page("app.py")
            st.stop()
        
        df = st.session_state.df
        
        try:
            if hasattr(df, 'empty') and df.empty:
                st.error("Le dataset est vide")
                st.stop()
                
            if len(df.columns) == 0:
                st.error("Le dataset n'a pas de colonnes")
                st.stop()
                
            return df
            
        except Exception as e:
            logger.error(f"Dataframe validation error: {e}")
            st.error(f"Erreur de validation: {str(e)[:200]}")
            st.stop()
    
    @staticmethod
    def is_valid_column_name(name: str) -> bool:
        """Valide un nom de colonne"""
        if not name or not isinstance(name, str) or len(name.strip()) == 0:
            return False
        
        name = name.strip()
        if len(name) > 50 or len(name) < 1:
            return False
        
        return bool(re.match(r'^[a-zA-Z][a-zA-Z0-9_-]*$', name))

df = DataValidator.validate_dataframe()

# Gestion du cache et hachage
@monitor_performance("dataset_hashing")
def get_dataset_hash(df) -> str:
    """GÃ©nÃ¨re un hash stable du dataset"""
    try:
        if is_dask_dataframe(df):
            return f"dask_{hash(tuple(sorted(df.columns)))}_{df.npartitions}_{st.session_state.dashboard_version}"
        else:
            shape_hash = hash((df.shape[0], df.shape[1]))
            return f"pandas_{hash(tuple(sorted(df.columns)))}_{shape_hash}_{st.session_state.dashboard_version}"
    except Exception as e:
        logger.warning(f"Hash calculation fallback: {e}")
        return f"fallback_{int(time.time())}"

# VÃ©rification du changement de dataset
current_hash = get_dataset_hash(df)
if st.session_state.dataset_hash != current_hash:
    logger.info(f"Dataset changed: {current_hash}")
    st.session_state.dataset_hash = current_hash
    st.session_state.column_types = None
    StateManager.reset_selections()

# Cache optimisÃ©
@st.cache_data(ttl=Config.CACHE_TTL, max_entries=20, show_spinner=False)
@monitor_performance("global_metrics")
def compute_global_metrics(_df) -> Dict[str, Any]:
    """Calcule les mÃ©triques globales avec gestion robuste"""
    try:
        n_rows = compute_if_dask(_df.shape[0]) if hasattr(_df, 'shape') else len(_df)
        n_cols = _df.shape[1] if hasattr(_df, 'shape') else 0
        
        # Valeurs manquantes
        try:
            total_missing = compute_if_dask(_df.isna().sum().sum())
            missing_percentage = (total_missing / (n_rows * n_cols)) * 100 if (n_rows * n_cols) > 0 else 0
        except Exception:
            total_missing = 0
            missing_percentage = 0
        
        # Doublons
        try:
            duplicate_rows = compute_if_dask(_df.duplicated().sum())
        except Exception:
            duplicate_rows = 0
        
        # MÃ©moire
        memory_usage = "N/A"
        try:
            if not is_dask_dataframe(_df):
                memory_bytes = compute_if_dask(_df.memory_usage(deep=True).sum())
                memory_usage = memory_bytes / (1024**2)
            else:
                memory_usage = f"Dask ({_df.npartitions} partitions)"
        except Exception:
            pass
        
        return {
            'n_rows': n_rows,
            'n_cols': n_cols,
            'missing_percentage': missing_percentage,
            'duplicate_rows': duplicate_rows,
            'memory_usage': memory_usage
        }
    except Exception as e:
        logger.error(f"Global metrics error: {e}")
        return {'n_rows': 0, 'n_cols': 0, 'missing_percentage': 0, 'duplicate_rows': 0, 'memory_usage': 'Error'}

@st.cache_data(ttl=Config.CACHE_TTL, max_entries=10)
@monitor_performance("column_detection")
def cached_auto_detect_column_types(_df) -> Dict[str, List]:
    """Cache la dÃ©tection des types de colonnes"""
    try:
        result = auto_detect_column_types(_df)
        required_keys = ['numeric', 'categorical', 'text_or_high_cardinality', 'datetime']
        for key in required_keys:
            if key not in result:
                result[key] = []
        return result
    except Exception as e:
        logger.error(f"Column type detection failed: {e}")
        return {key: [] for key in ['numeric', 'categorical', 'text_or_high_cardinality', 'datetime']}

# Ã‰chantillonnage optimisÃ©
class DataSampler:
    """Gestion optimisÃ©e de l'Ã©chantillonnage"""
    
    @staticmethod
    @monitor_performance("data_sampling")
    def get_sample(df, max_rows: int = Config.MAX_SAMPLE_SIZE, random_state: int = 42) -> pd.DataFrame:
        """Retourne un Ã©chantillon optimisÃ©"""
        try:
            total_rows = compute_if_dask(df.shape[0])
            
            if total_rows <= max_rows:
                if is_dask_dataframe(df):
                    return compute_if_dask(df.head(max_rows))
                else:
                    return df.copy()
            
            sample_fraction = min(0.1, max_rows / total_rows)
            
            if is_dask_dataframe(df):
                sample = df.sample(frac=sample_fraction, random_state=random_state).head(max_rows)
                return compute_if_dask(sample)
            else:
                return df.sample(n=max_rows, random_state=random_state, replace=False)
                
        except Exception as e:
            logger.error(f"Sampling error: {e}")
            fallback_size = min(1000, total_rows) if 'total_rows' in locals() else 1000
            if is_dask_dataframe(df):
                return compute_if_dask(df.head(fallback_size))
            else:
                return df.head(fallback_size)

# Calculer les types de colonnes si nÃ©cessaire
if st.session_state.column_types is None:
    with st.spinner("ðŸ” Analyse des types de colonnes..."):
        st.session_state.column_types = cached_auto_detect_column_types(df)

column_types = st.session_state.column_types

# Vue d'ensemble
st.header("ðŸ“‹ Vue d'ensemble du jeu de donnÃ©es")

try:
    overview_metrics = compute_global_metrics(df)
    fig = plot_overview_metrics(overview_metrics)
    if fig:
        st.plotly_chart(fig, width='stretch', config={'responsive': True})
    else:
        st.info("ðŸ“Š MÃ©triques globales non disponibles")
except Exception as e:
    st.error(f"Erreur mÃ©triques: {str(e)[:100]}")

# Info colonnes optimisÃ©e
col_count = len(df.columns)
if col_count > 8:
    col_info = f"**{col_count} colonnes** : {', '.join(list(df.columns)[:6])}... +{col_count-6}"
else:
    col_info = f"**{col_count} colonnes** : {', '.join(list(df.columns))}"
st.info(col_info)

# Onglets avec gestion stable
tabs = st.tabs(["ðŸ“ˆ QualitÃ©", "ðŸ”¬ Variables", "ðŸ”— Relations", "ðŸŒ CorrÃ©lations", "ðŸ“„ AperÃ§u", "ðŸ—‘ï¸ Nettoyage"])

# Onglet 1: QualitÃ© des donnÃ©es
with tabs[0]:
    st.subheader("ðŸ“Š QualitÃ© des DonnÃ©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        try:
            missing_fig = plot_missing_values_overview(df)
            if missing_fig:
                st.plotly_chart(missing_fig, width='stretch', config={'responsive': True})
            else:
                st.success("âœ… Aucune valeur manquante")
        except Exception as e:
            st.error("Erreur valeurs manquantes")
            logger.error(f"Missing values plot: {e}")
    
    with col2:
        try:
            cardinality_fig = plot_cardinality_overview(df, column_types)
            if cardinality_fig:
                st.plotly_chart(cardinality_fig, width='stretch', config={'responsive': True})
            else:
                st.info("ðŸ“Š CardinalitÃ© uniforme")
        except Exception as e:
            st.error("Erreur cardinalitÃ©")
            logger.error(f"Cardinality plot: {e}")

# Onglet 2: Analyse univariÃ©e
with tabs[1]:
    st.subheader("ðŸ” Analyse UnivariÃ©e")
    
    available_columns = list(df.columns)
    if not available_columns:
        st.warning("Aucune colonne disponible")
    else:
        # SÃ©lecteur stable avec Ã©tat persistant
        if not st.session_state.selected_univar_col or st.session_state.selected_univar_col not in available_columns:
            st.session_state.selected_univar_col = available_columns[0]
        
        selected_col = st.selectbox(
            "Variable Ã  analyser :",
            options=available_columns,
            index=available_columns.index(st.session_state.selected_univar_col),
            format_func=lambda x: f"{x} ({'NumÃ©rique' if x in column_types.get('numeric', []) else 'CatÃ©gorielle'})",
            key="univar_selector"
        )
        
        # Mise Ã  jour de l'Ã©tat seulement si nÃ©cessaire
        if selected_col != st.session_state.selected_univar_col:
            st.session_state.selected_univar_col = selected_col
        
        if selected_col:
            try:
                sample_df = DataSampler.get_sample(df)
                col_data = sample_df[selected_col].dropna()
                
                if col_data.empty:
                    st.warning(f"Aucune donnÃ©e valide pour **{selected_col}**")
                else:
                    if selected_col in column_types.get('numeric', []):
                        # Statistiques numÃ©riques
                        stats_cols = st.columns(4)
                        with stats_cols[0]:
                            st.metric("Moyenne", f"{col_data.mean():.3f}")
                        with stats_cols[1]:
                            st.metric("MÃ©diane", f"{col_data.median():.3f}")
                        with stats_cols[2]:
                            st.metric("Ã‰cart-type", f"{col_data.std():.3f}")
                        with stats_cols[3]:
                            st.metric("Uniques", f"{col_data.nunique():,}")
                        
                        # Graphique
                        with st.spinner("ðŸ“Š GÃ©nÃ©ration du graphique..."):
                            fig = plot_distribution(col_data, selected_col)
                            if fig:
                                st.plotly_chart(fig, width='stretch', config={'responsive': True})
                            else:
                                st.info("Graphique non disponible")
                    else:
                        # Variable catÃ©gorielle
                        value_counts = col_data.value_counts().head(20)
                        
                        if not value_counts.empty:
                            col_chart, col_table = st.columns([2, 1])
                            
                            with col_table:
                                df_display = value_counts.reset_index()
                                df_display.columns = ['Valeur', 'Count']
                                st.dataframe(df_display, height=400, width='stretch')
                            
                            with col_chart:
                                import plotly.express as px
                                fig = px.bar(
                                    x=value_counts.index.astype(str),
                                    y=value_counts.values,
                                    labels={'x': selected_col, 'y': 'FrÃ©quence'},
                                    title=f"Distribution de {selected_col}"
                                )
                                fig.update_layout(template="plotly_white", height=400)
                                st.plotly_chart(fig, width='stretch', config={'responsive': True})
                        else:
                            st.info("Aucune donnÃ©e Ã  afficher")
                            
            except Exception as e:
                st.error(f"Erreur analyse de {selected_col}")
                logger.error(f"Univariate analysis error for {selected_col}: {e}")

# Onglet 3: Relations bivariÃ©es
with tabs[2]:
    st.subheader("ðŸ”— Relations entre Variables")
    
    available_columns = list(df.columns)
    
    if len(available_columns) >= 2:
        # Ã‰tats persistants pour sÃ©lections
        if not st.session_state.selected_bivar_col1 or st.session_state.selected_bivar_col1 not in available_columns:
            st.session_state.selected_bivar_col1 = available_columns[0]
        
        if not st.session_state.selected_bivar_col2 or st.session_state.selected_bivar_col2 not in available_columns:
            st.session_state.selected_bivar_col2 = available_columns[1] if len(available_columns) > 1 else available_columns[0]
        
        col1, col2 = st.columns(2)
        
        with col1:
            var1 = st.selectbox(
                "Variable 1",
                options=available_columns,
                index=available_columns.index(st.session_state.selected_bivar_col1),
                key="bivar_var1"
            )
            if var1 != st.session_state.selected_bivar_col1:
                st.session_state.selected_bivar_col1 = var1
        
        with col2:
            var2 = st.selectbox(
                "Variable 2",
                options=available_columns,
                index=available_columns.index(st.session_state.selected_bivar_col2),
                key="bivar_var2"
            )
            if var2 != st.session_state.selected_bivar_col2:
                st.session_state.selected_bivar_col2 = var2
        
        if var1 != var2:
            try:
                type1 = 'numeric' if var1 in column_types.get('numeric', []) else 'categorical'
                type2 = 'numeric' if var2 in column_types.get('numeric', []) else 'categorical'
                
                sample_df = DataSampler.get_sample(df, Config.MAX_BIVARIATE_SAMPLE)
                
                if not sample_df[[var1, var2]].empty:
                    with st.spinner("ðŸ“Š GÃ©nÃ©ration de l'analyse bivariÃ©e..."):
                        biv_fig = plot_bivariate_analysis(sample_df, var1, var2, type1, type2)
                        if biv_fig:
                            st.plotly_chart(biv_fig, width='stretch', config={'responsive': True})
                        else:
                            st.info("Graphique non disponible pour cette combinaison")
                else:
                    st.warning("DonnÃ©es insuffisantes")
                    
            except Exception as e:
                st.error("Erreur analyse bivariÃ©e")
                logger.error(f"Bivariate analysis error: {e}")
        else:
            st.warning("SÃ©lectionnez deux variables diffÃ©rentes")
    else:
        st.warning("Au moins 2 colonnes nÃ©cessaires")

# Avant l'onglet qui suivent c'est une fonction de fallback pour afficher la corrÃ©lation 
# Plus simple si dans pltos/exploratory Ã§a plante
import plotly.express as px
def create_simple_correlation_heatmap(df, max_cols=20):
    """Version ultra-simple du heatmap pour les cas problÃ©matiques"""
    try:
        # Prendre seulement les colonnes numÃ©riques
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        
        if len(numeric_cols) > max_cols:
            # Prendre les colonnes avec le moins de valeurs manquantes
            missing_rates = df[numeric_cols].isnull().mean()
            numeric_cols = missing_rates.nsmallest(max_cols).index.tolist()
        
        if len(numeric_cols) < 2:
            return None
            
        # Calcul de corrÃ©lation simple
        corr_matrix = df[numeric_cols].corr()
        
        fig = px.imshow(
            corr_matrix,
            text_auto=".2f",
            aspect="auto",
            color_continuous_scale='RdBu',
            range_color=[-1, 1],
            title=f"Matrice de corrÃ©lation ({len(numeric_cols)} variables)"
        )
        
        fig.update_layout(height=600)
        return fig, numeric_cols
        
    except Exception as e:
        logger.error(f"Simple heatmap failed: {e}")
        return None

# Onglet 4: CorrÃ©lations - VERSION CORRIGÃ‰E
with tabs[3]:
    st.subheader("ðŸŒ Matrice de CorrÃ©lations")
    
    # Options de configuration simplifiÃ©es
    col_config1, col_config2 = st.columns(2)
    
    with col_config1:
        # SÃ©lecteur de colonnes numÃ©riques seulement
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        if numeric_cols:
            target_col = st.selectbox(
                "Variable cible (optionnelle)", 
                options=[None] + numeric_cols,
                key="corr_target_select"
            )
        else:
            st.warning("Aucune variable numÃ©rique disponible")
            target_col = None
    
    with col_config2:
        # Option pour forcer le mode simple
        use_simple_mode = st.checkbox("Mode simple (recommandÃ©)", value=True, key="simple_mode")
    
    if st.button("ðŸ”„ GÃ©nÃ©rer la matrice", type="primary", key="generate_corr"):
        with st.spinner("ðŸ“Š Calcul des corrÃ©lations..."):
            try:
                # Ã‰chantillonner pour les performances
                sample_df = DataSampler.get_sample(df, max_rows=3000)  # RÃ©duit la taille
                
                if use_simple_mode:
                    # Utiliser la version simple
                    corr_fig, used_cols = create_simple_correlation_heatmap(sample_df, max_cols=15)
                else:
                    # Utiliser la version complÃ¨te
                    corr_fig, used_cols = plot_correlation_heatmap(
                        sample_df, 
                        target_column=target_col,
                        task_type="classification" if target_col else None
                    )
                
                if corr_fig:
                    st.plotly_chart(corr_fig, width='stretch', config={'responsive': True})
                    st.success(f"âœ… Matrice gÃ©nÃ©rÃ©e avec {len(used_cols)} variables")
                else:
                    st.warning("âŒ Impossible de gÃ©nÃ©rer la matrice")
                    # Fallback ultime
                    st.info("Essayez avec le mode simple activÃ©")
                    
            except Exception as e:
                st.error("Erreur lors du calcul des corrÃ©lations")
                logger.error(f"Correlation error: {e}")
                
                # Fallback direct avec Plotly Express
                try:
                    st.info("Tentative avec mÃ©thode alternative...")
                    numeric_cols = sample_df.select_dtypes(include=[np.number]).columns
                    if len(numeric_cols) > 1:
                        corr_matrix = sample_df[numeric_cols].corr()
                        fig = px.imshow(corr_matrix, text_auto=".2f", aspect="auto")
                        st.plotly_chart(fig, width='stretch')
                    else:
                        st.info("Pas assez de variables numÃ©riques")
                except Exception as fallback_e:
                    st.error("Ã‰chec de toutes les mÃ©thodes")

# Onglet 5: AperÃ§u donnÃ©es brutes - COMPLÃ‰TÃ‰
with tabs[4]:
    st.subheader("ðŸ“„ AperÃ§u des DonnÃ©es Brutes")
    
    try:
        # Utiliser df_raw si disponible, sinon df
        raw_df = st.session_state.get('df_raw', df)
        total_rows = compute_if_dask(raw_df.shape[0])
        
        # Configuration de l'aperÃ§u
        col_config1, col_config2, col_config3 = st.columns(3)
        
        with col_config1:
            preview_size = st.slider(
                "Nombre de lignes Ã  afficher",
                min_value=10,
                max_value=min(500, total_rows),
                value=min(Config.MAX_PREVIEW_ROWS, total_rows),
                key="preview_size_slider"
            )
        
        with col_config2:
            show_from_start = st.radio("Affichage", ["DÃ©but", "Ã‰chantillon"], key="preview_type")
        
        with col_config3:
            show_dtypes = st.checkbox("Afficher les types", value=False, key="show_dtypes")
        
        # PrÃ©paration des donnÃ©es Ã  afficher
        if show_from_start == "DÃ©but":
            display_df = compute_if_dask(raw_df.head(preview_size))
        else:
            display_df = DataSampler.get_sample(raw_df, preview_size)
        
        # Gestion des colonnes avec beaucoup de texte
        display_df_truncated = display_df.copy()
        for col in display_df_truncated.select_dtypes(include=['object']).columns:
            display_df_truncated[col] = display_df_truncated[col].astype(str).apply(
                lambda x: x[:50] + "..." if len(str(x)) > 50 else x
            )
        
        # Affichage principal
        st.dataframe(
            display_df_truncated,
            height=400,
            width='stretch'
        )
        
        # Affichage des types de donnÃ©es si demandÃ©
        if show_dtypes:
            with st.expander("ðŸ“Š Types de donnÃ©es des colonnes"):
                dtypes_info = []
                for col in display_df.columns:
                    dtype = str(display_df[col].dtype)
                    non_null_count = display_df[col].count()
                    total_count = len(display_df[col])
                    null_percentage = ((total_count - non_null_count) / total_count * 100) if total_count > 0 else 0
                    
                    dtypes_info.append({
                        'Colonne': col,
                        'Type': dtype,
                        'Non-null': non_null_count,
                        'Null (%)': f"{null_percentage:.1f}%"
                    })
                
                dtypes_df = pd.DataFrame(dtypes_info)
                st.dataframe(dtypes_df, width='stretch')
        
        # Informations complÃ©mentaires
        info_col1, info_col2, info_col3 = st.columns(3)
        
        with info_col1:
            st.caption(f"ðŸ“Š {len(display_df)} lignes affichÃ©es sur {total_rows:,} total")
        
        with info_col2:
            st.caption(f"ðŸ“‹ {len(display_df.columns)} colonnes")
        
        with info_col3:
            if len(display_df) > 0 and len(display_df.columns) > 0:
                missing_pct = (display_df.isnull().sum().sum() / (len(display_df) * len(display_df.columns))) * 100
                st.caption(f"ðŸ•³ï¸ {missing_pct:.1f}% valeurs manquantes")
            else:
                st.caption("ðŸ•³ï¸ DonnÃ©es insuffisantes")
        
        # Bouton de tÃ©lÃ©chargement de l'Ã©chantillon
        st.markdown("---")
        col_download1, col_download2 = st.columns([3, 1])
        
        with col_download2:
            if st.button("ðŸ’¾ TÃ©lÃ©charger l'Ã©chantillon", key="download_sample"):
                try:
                    csv = display_df.to_csv(index=False)
                    st.download_button(
                        label="ðŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f"echantillon_donnees_{time.strftime('%Y%m%d_%H%M')}.csv",
                        mime="text/csv",
                        key="download_csv"
                    )
                except Exception as download_error:
                    st.error("âŒ Erreur lors de la prÃ©paration du tÃ©lÃ©chargement")
                    logger.error(f"Download error: {download_error}")
    
    except Exception as e:
        st.error("âŒ Erreur lors de l'affichage de l'aperÃ§u des donnÃ©es")
        logger.error(f"Data preview error: {e}")
        
        # Fallback simple
        try:
            st.info("ðŸ”„ Tentative de chargement simplifiÃ©...")
            fallback_df = compute_if_dask(df.head(50))
            st.dataframe(fallback_df, height=300, width='stretch')
            st.caption(f"ðŸ“Š Affichage de secours: 50 premiÃ¨res lignes sur {compute_if_dask(df.shape[0]):,} total")
        except Exception as fallback_error:
            st.error("ðŸš¨ Impossible d'afficher les donnÃ©es")
            logger.error(f"Fallback preview also failed: {fallback_error}")

# Onglet 6: Nettoyage des donnÃ©es 
with tabs[5]:
    st.subheader("ðŸ—‘ï¸ Nettoyage des DonnÃ©es")
    
    st.markdown("### ðŸ” DÃ©tection des colonnes inutiles")
    
    # Choix du mode : automatique ou manuel
    mode = st.radio(
        "Mode de sÃ©lection des colonnes Ã  supprimer :",
        options=["Automatique", "Manuelle"],
        horizontal=True
    )
    
    cols_to_remove = []

    # --- Mode automatique ---
    if mode == "Automatique":
        col_detect, col_action = st.columns([2, 1])
        with col_detect:
            if st.button("ðŸ”Ž Analyser les colonnes inutiles", key="analyze_useless"):
                with st.spinner("Analyse en cours..."):
                    try:
                        useless_cols = detect_useless_columns(df, threshold_missing=0.7)
                        st.session_state.useless_candidates = useless_cols
                        
                        if useless_cols:
                            st.success(f"âœ… {len(useless_cols)} colonne(s) potentiellement inutile(s) dÃ©tectÃ©e(s)")
                            st.write(
                                "**Colonnes dÃ©tectÃ©es:**",
                                ", ".join(useless_cols[:5]) + ("..." if len(useless_cols) > 5 else "")
                            )
                            cols_to_remove = useless_cols
                        else:
                            st.info("ðŸŽ‰ Aucune colonne inutile dÃ©tectÃ©e")
                    except Exception as e:
                        st.error("âŒ Erreur lors de l'analyse")
                        logger.error(f"Useless columns detection error: {e}")
        
        with col_action:
            if st.session_state.useless_candidates:
                if st.button("ðŸ—‘ï¸ Supprimer les colonnes inutiles", type="primary"):
                    try:
                        valid_cols = [col for col in st.session_state.useless_candidates if col in df.columns]
                        if valid_cols:
                            if is_dask_dataframe(df):
                                new_df = df.drop(columns=valid_cols).persist()
                            else:
                                new_df = df.drop(columns=valid_cols)
                            st.session_state.df = new_df
                            st.session_state.useless_candidates = []
                            st.session_state.column_types = None
                            st.session_state.dashboard_version += 1
                            st.success(f"âœ… {len(valid_cols)} colonne(s) supprimÃ©e(s)")
                            st.rerun()
                        else:
                            st.warning("âš ï¸ Aucune colonne valide Ã  supprimer")
                    except Exception as e:
                        st.error("âŒ Erreur lors de la suppression")
                        logger.error(f"Column removal error: {e}")

    # --- Mode manuel ---
    else:
        all_cols = df.columns.tolist()
        cols_to_remove = st.multiselect(
            "SÃ©lectionnez les colonnes Ã  supprimer",
            options=all_cols,
            default=[]
        )
        if cols_to_remove:
            if st.button("ðŸ—‘ï¸ Supprimer les colonnes sÃ©lectionnÃ©es", type="primary"):
                try:
                    valid_cols = [col for col in cols_to_remove if col in df.columns]
                    if valid_cols:
                        if is_dask_dataframe(df):
                            new_df = df.drop(columns=valid_cols).persist()
                        else:
                            new_df = df.drop(columns=valid_cols)
                        st.session_state.df = new_df
                        st.session_state.column_types = None
                        st.session_state.dashboard_version += 1
                        st.success(f"âœ… {len(valid_cols)} colonne(s) supprimÃ©e(s)")
                        st.rerun()
                    else:
                        st.warning("âš ï¸ Aucune colonne valide Ã  supprimer")
                except Exception as e:
                    st.error("âŒ Erreur lors de la suppression")
                    logger.error(f"Manual column removal error: {e}")

    st.markdown("---")
    st.markdown("### âœï¸ Renommage des colonnes")
    
    col_rename1, col_rename2 = st.columns(2)
    
    with col_rename1:
        if df.columns.tolist():
            col_to_rename = st.selectbox(
                "Colonne Ã  renommer",
                options=df.columns.tolist(),
                key="rename_select"
            )
        else:
            col_to_rename = None
            st.warning("Aucune colonne disponible")
    
    with col_rename2:
        new_name = st.text_input(
            "Nouveau nom",
            placeholder="Nouveau nom de colonne",
            key="rename_input"
        )
    
    col_add, col_clear = st.columns(2)
    
    with col_add:
        if st.button("âž• Ajouter au plan de renommage", key="add_rename"):
            if col_to_rename and new_name and DataValidator.is_valid_column_name(new_name):
                if new_name not in df.columns:
                    if (col_to_rename, new_name) not in st.session_state.rename_list:
                        st.session_state.rename_list.append((col_to_rename, new_name))
                        st.success(f"âœ… {col_to_rename} â†’ {new_name} ajoutÃ©")
                    else:
                        st.warning("âš ï¸ Ce renommage est dÃ©jÃ  planifiÃ©")
                else:
                    st.error("âŒ Ce nom de colonne existe dÃ©jÃ ")
            else:
                st.error("âŒ Nom invalide ou vide")
    
    with col_clear:
        if st.button("ðŸ—‘ï¸ Vider la liste", key="clear_renames"):
            st.session_state.rename_list = []
            st.success("âœ… Liste vidÃ©e")
    
    # Affichage des renommages planifiÃ©s
    if st.session_state.rename_list:
        st.markdown("**ðŸ“‹ Renommages planifiÃ©s:**")
        rename_df = pd.DataFrame(st.session_state.rename_list, columns=["Ancien nom", "Nouveau nom"])
        st.dataframe(rename_df, width='stretch')
        
        if st.button("âœ… Appliquer tous les renommages", type="primary", key="apply_renames"):
            try:
                rename_dict = dict(st.session_state.rename_list)
                valid_renames = {old: new for old, new in rename_dict.items() if old in df.columns}
                
                if valid_renames:
                    if is_dask_dataframe(df):
                        new_df = df.rename(columns=valid_renames).persist()
                    else:
                        new_df = df.rename(columns=valid_renames)
                    st.session_state.df = new_df
                    st.session_state.rename_list = []
                    st.session_state.column_types = None
                    st.session_state.dashboard_version += 1
                    st.success(f"âœ… {len(valid_renames)} colonne(s) renommÃ©e(s)")
                    st.rerun()
                else:
                    st.warning("âš ï¸ Aucun renommage valide Ã  appliquer")
            except Exception as e:
                st.error("âŒ Erreur lors du renommage")
                logger.error(f"Rename error: {e}")

    st.markdown("---")
    st.markdown("### ðŸ› ï¸ Actions de maintenance")
    
    col_maint1, col_maint2 = st.columns(2)
    
    with col_maint1:
        if st.button("ðŸ§¹ Nettoyer la mÃ©moire", key="cleanup_mem"):
            try:
                cleanup_memory()
                st.success("âœ… MÃ©moire nettoyÃ©e")
            except Exception as e:
                st.error("âŒ Erreur de nettoyage")
    
    with col_maint2:
        if st.button("ðŸ”„ RafraÃ®chir l'analyse", key="refresh_analysis"):
            try:
                st.session_state.column_types = None
                st.cache_data.clear()
                st.success("âœ… Analyse rafraÃ®chie")
                st.rerun()
            except Exception as e:
                st.error("âŒ Erreur de rafraÃ®chissement")

# Footer final avec informations systÃ¨me
st.markdown("---")
footer_cols = st.columns(4)

with footer_cols[0]:
    try:
        n_rows = compute_if_dask(df.shape[0])
        n_cols = df.shape[1]
        st.caption(f"ðŸ“Š {n_rows:,} Ã— {n_cols}")
    except:
        st.caption("ðŸ“Š DonnÃ©es non disponibles")

with footer_cols[1]:
    try:
        if not is_dask_dataframe(df):
            memory_mb = compute_if_dask(df.memory_usage(deep=True).sum()) / (1024**2)
            st.caption(f"ðŸ’¾ {memory_mb:.1f} MB")
        else:
            st.caption(f"ðŸ’¾ {df.npartitions} partitions")
    except:
        st.caption("ðŸ’¾ N/A")

with footer_cols[2]:
    try:
        sys_mem = psutil.virtual_memory().percent
        status = "ðŸ”´" if sys_mem > Config.MEMORY_CRITICAL else "ðŸŸ¡" if sys_mem > Config.MEMORY_WARNING else "ðŸŸ¢"
        st.caption(f"{status} {sys_mem:.0f}% RAM")
    except:
        st.caption("ðŸ”§ RAM: N/A")

with footer_cols[3]:
    st.caption(f"ðŸ•’ {time.strftime('%H:%M:%S')}")

# Nettoyage final
gc.collect()