import os
import streamlit as st
import pandas as pd
import time
import logging
import re
import psutil
import gc
import numpy as np
from functools import wraps
from typing import Dict, List, Any

from src.data.data_analysis import (
    compute_if_dask,
    is_dask_dataframe,
    auto_detect_column_types,
    detect_useless_columns,
    cleanup_memory
)
from src.evaluation.exploratory_plots import (
    create_simple_correlation_heatmap,
    plot_overview_metrics,
    plot_missing_values_overview,
    plot_cardinality_overview,
    plot_distribution,
    plot_bivariate_analysis,
    plot_correlation_heatmap
)

# Configuration du logging avec rotation
import logging.handlers
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.handlers.RotatingFileHandler('logs/dashboard.log', maxBytes=10*1024*1024, backupCount=5),
        logging.StreamHandler()
    ]
)

from src.shared.logging import get_logger
logger = get_logger(__name__)

# Configuration Streamlit pour la production
st.set_page_config(
    page_title="Dashboard Analytics", 
    page_icon="üìä", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS personnalis√© pour un style moderne
st.markdown("""
<style>
    .main-header {
        font-size: 2rem;
        color: #2c3e50;
        text-align: center;
        margin-bottom: 1.5rem;
        font-weight: bold;
    }
    .tab-content {
        padding: 1rem;
        background: #f9f9f9;
        border-radius: 8px;
        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
    }
    .btn-primary {
        background-color: #3498db;
        color: white;
    }
    .btn-primary:hover {
        background-color: #2980b9;
    }
</style>
""", unsafe_allow_html=True)

# Constantes de configuration
class Config:
    MAX_PREVIEW_ROWS = 100
    MAX_SAMPLE_SIZE = 15000
    MAX_BIVARIATE_SAMPLE = 10000
    MEMORY_CHECK_INTERVAL = 180  # 3 minutes
    CACHE_TTL = 600  # 10 minutes
    TIMEOUT_THRESHOLD = 30
    MEMORY_WARNING = 85
    MEMORY_CRITICAL = 90

# Configuration production
def setup_production_environment():
    """Configuration optimis√©e pour l'environnement de production"""
    if 'production_setup_done' not in st.session_state:
        st.session_state.production_setup_done = True
        
        if os.getenv('STREAMLIT_ENV') == 'production':
            hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            .stDeployButton {display:none;}
            footer {visibility: hidden;}
            #stDecoration {display:none;}
            .stAlert > div {padding: 0.5rem;}
            .element-container {margin: 0.5rem 0;}
            </style>
            """
            st.markdown(hide_streamlit_style, unsafe_allow_html=True)

setup_production_environment()

# D√©corateur de monitoring avanc√©
def monitor_performance(operation_name: str = ""):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                elapsed = time.time() - start_time
                
                if elapsed > 5:
                    logger.warning(f"SLOW: {operation_name or func.__name__} took {elapsed:.2f}s")
                
                return result
            except Exception as e:
                elapsed = time.time() - start_time
                logger.error(f"ERROR in {operation_name or func.__name__}: {str(e)} after {elapsed:.2f}s")
                raise
        return wrapper
    return decorator

st.title("üìä Dashboard Exploratoire")

# Gestion d'√©tat centralis√©e et robuste
class StateManager:
    """Gestion centralis√©e de l'√©tat du dashboard"""
    
    REQUIRED_KEYS = {
        'column_types': (dict, type(None)),
        'rename_list': list,
        'columns_to_drop': list,
        'useless_candidates': list,
        'dataset_hash': (str, type(None)),
        'last_memory_check': (int, float),
        'dashboard_version': int,
        'selected_univar_col': (str, type(None)),
        'selected_bivar_col1': (str, type(None)),
        'selected_bivar_col2': (str, type(None))
    }
    
    @classmethod
    def initialize(cls):
        """Initialise l'√©tat avec validation"""
        defaults = {
            'column_types': None,
            'rename_list': [],
            'columns_to_drop': [],
            'useless_candidates': [],
            'dataset_hash': None,
            'last_memory_check': 0,
            'dashboard_version': 1,
            'selected_univar_col': None,
            'selected_bivar_col1': None,
            'selected_bivar_col2': None
        }
        
        for key, expected_type in cls.REQUIRED_KEYS.items():
            if key not in st.session_state:
                st.session_state[key] = defaults[key]
            elif not isinstance(st.session_state[key], expected_type):
                logger.warning(f"Invalid type for {key}, resetting")
                st.session_state[key] = defaults[key]
    
    @classmethod
    def reset_selections(cls):
        """Reset les s√©lections pour √©viter les erreurs"""
        selection_keys = ['selected_univar_col', 'selected_bivar_col1', 'selected_bivar_col2']
        for key in selection_keys:
            st.session_state[key] = None

StateManager.initialize()

# Monitoring syst√®me optimis√©
class SystemMonitor:
    """Monitoring syst√®me avec seuils configurables"""
    
    @classmethod
    @monitor_performance("system_check")
    def check_resources(cls):
        """V√©rifie les ressources syst√®me"""
        current_time = time.time()
        if current_time - st.session_state.last_memory_check > Config.MEMORY_CHECK_INTERVAL:
            try:
                memory_info = psutil.virtual_memory()
                memory_percent = memory_info.percent
                
                if memory_percent > Config.MEMORY_CRITICAL:
                    st.error(f"üö® M√©moire critique: {memory_percent:.1f}%")
                    cls._emergency_cleanup()
                elif memory_percent > Config.MEMORY_WARNING:
                    st.warning(f"‚ö†Ô∏è M√©moire √©lev√©e: {memory_percent:.1f}%")
                    cls._show_cleanup_option()
                
                st.session_state.last_memory_check = current_time
                
            except Exception as e:
                logger.error(f"System check failed: {e}")
    
    @staticmethod
    def _emergency_cleanup():
        """Nettoyage d'urgence"""
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("üßπ Nettoyer", type="primary", key="emergency_clean"):
                cleanup_memory()
                st.cache_data.clear()
                gc.collect()
                st.success("M√©moire nettoy√©e")
                st.rerun()
    
    @staticmethod
    def _show_cleanup_option():
        """Option de nettoyage standard"""
        col1, col2 = st.columns([4, 1])
        with col2:
            if st.button("üßπ", help="Nettoyer m√©moire", key="normal_clean"):
                cleanup_memory()
                st.success("‚úÖ Nettoy√©")
                st.rerun()

SystemMonitor.check_resources()

# Validation des donn√©es
class DataValidator:
    """Validation et gestion des donn√©es"""
    
    @staticmethod
    @monitor_performance("validate_dataframe")
    def validate_dataframe() -> pd.DataFrame:
        """Valide le DataFrame avec gestion d'erreurs"""
        if 'df' not in st.session_state or st.session_state.df is None:
            st.error("üìä Aucun dataset charg√©")
            st.info("Chargez un dataset depuis la page d'accueil pour commencer l'analyse.")
            if st.button("üè† Retour √† l'accueil"):
                st.switch_page("app.py")
            st.stop()
        
        df = st.session_state.df
        
        try:
            if hasattr(df, 'empty') and df.empty:
                st.error("Le dataset est vide")
                st.stop()
                
            if len(df.columns) == 0:
                st.error("Le dataset n'a pas de colonnes")
                st.stop()
                
            return df
            
        except Exception as e:
            logger.error(f"Dataframe validation error: {e}")
            st.error(f"Erreur de validation: {str(e)[:200]}")
            st.stop()
    
    @staticmethod
    def is_valid_column_name(name: str) -> bool:
        """Valide un nom de colonne"""
        if not name or not isinstance(name, str) or len(name.strip()) == 0:
            return False
        
        name = name.strip()
        if len(name) > 50 or len(name) < 1:
            return False
        
        return bool(re.match(r'^[a-zA-Z][a-zA-Z0-9_-]*$', name))

df = DataValidator.validate_dataframe()

# Gestion du cache et hachage
@monitor_performance("dataset_hashing")
def get_dataset_hash(df) -> str:
    """G√©n√®re un hash stable du dataset"""
    try:
        if is_dask_dataframe(df):
            return f"dask_{hash(tuple(sorted(df.columns)))}_{df.npartitions}_{st.session_state.dashboard_version}"
        else:
            shape_hash = hash((df.shape[0], df.shape[1]))
            return f"pandas_{hash(tuple(sorted(df.columns)))}_{shape_hash}_{st.session_state.dashboard_version}"
    except Exception as e:
        logger.warning(f"Hash calculation fallback: {e}")
        return f"fallback_{int(time.time())}"

# V√©rification du changement de dataset
current_hash = get_dataset_hash(df)
if st.session_state.dataset_hash != current_hash:
    logger.info(f"Dataset changed: {current_hash}")
    st.session_state.dataset_hash = current_hash
    st.session_state.column_types = None
    StateManager.reset_selections()

# Cache optimis√©
@st.cache_data(ttl=Config.CACHE_TTL, max_entries=20, show_spinner=False)
@monitor_performance("global_metrics")
def compute_global_metrics(_df) -> Dict[str, Any]:
    """Calcule les m√©triques globales avec gestion robuste"""
    try:
        n_rows = compute_if_dask(_df.shape[0]) if hasattr(_df, 'shape') else len(_df)
        n_cols = _df.shape[1] if hasattr(_df, 'shape') else 0
        
        # Valeurs manquantes
        try:
            total_missing = compute_if_dask(_df.isna().sum().sum())
            missing_percentage = (total_missing / (n_rows * n_cols)) * 100 if (n_rows * n_cols) > 0 else 0
        except Exception:
            total_missing = 0
            missing_percentage = 0
        
        # Doublons
        try:
            duplicate_rows = compute_if_dask(_df.duplicated().sum())
        except Exception:
            duplicate_rows = 0
        
        # M√©moire
        memory_usage = "N/A"
        try:
            if not is_dask_dataframe(_df):
                memory_bytes = compute_if_dask(_df.memory_usage(deep=True).sum())
                memory_usage = memory_bytes / (1024**2)
            else:
                memory_usage = f"Dask ({_df.npartitions} partitions)"
        except Exception:
            pass
        
        return {
            'n_rows': n_rows,
            'n_cols': n_cols,
            'missing_percentage': missing_percentage,
            'duplicate_rows': duplicate_rows,
            'memory_usage': memory_usage
        }
    except Exception as e:
        logger.error(f"Global metrics error: {e}")
        return {'n_rows': 0, 'n_cols': 0, 'missing_percentage': 0, 'duplicate_rows': 0, 'memory_usage': 'Error'}

@st.cache_data(ttl=Config.CACHE_TTL, max_entries=10)
@monitor_performance("column_detection")
def cached_auto_detect_column_types(_df) -> Dict[str, List]:
    """Cache la d√©tection des types de colonnes"""
    try:
        result = auto_detect_column_types(_df)
        required_keys = ['numeric', 'categorical', 'text_or_high_cardinality', 'datetime']
        for key in required_keys:
            if key not in result:
                result[key] = []
        return result
    except Exception as e:
        logger.error(f"Column type detection failed: {e}")
        return {key: [] for key in ['numeric', 'categorical', 'text_or_high_cardinality', 'datetime']}

# √âchantillonnage optimis√©
class DataSampler:
    """Gestion optimis√©e de l'√©chantillonnage"""
    
    @staticmethod
    @monitor_performance("data_sampling")
    def get_sample(df, max_rows: int = Config.MAX_SAMPLE_SIZE, random_state: int = 42) -> pd.DataFrame:
        """Retourne un √©chantillon optimis√©"""
        try:
            total_rows = compute_if_dask(df.shape[0])
            
            if total_rows <= max_rows:
                if is_dask_dataframe(df):
                    return compute_if_dask(df.head(max_rows))
                else:
                    return df.copy()
            
            sample_fraction = min(0.1, max_rows / total_rows)
            
            if is_dask_dataframe(df):
                sample = df.sample(frac=sample_fraction, random_state=random_state).head(max_rows)
                return compute_if_dask(sample)
            else:
                return df.sample(n=max_rows, random_state=random_state, replace=False)
                
        except Exception as e:
            logger.error(f"Sampling error: {e}")
            fallback_size = min(1000, total_rows) if 'total_rows' in locals() else 1000
            if is_dask_dataframe(df):
                return compute_if_dask(df.head(fallback_size))
            else:
                return df.head(fallback_size)

# Calculer les types de colonnes si n√©cessaire
if st.session_state.column_types is None:
    with st.spinner("üîç Analyse des types de colonnes..."):
        st.session_state.column_types = cached_auto_detect_column_types(df)

column_types = st.session_state.column_types

# Vue d'ensemble
st.header("üìã Vue d'ensemble du jeu de donn√©es")

try:
    overview_metrics = compute_global_metrics(df)
    fig = plot_overview_metrics(overview_metrics)
    if fig:
        st.plotly_chart(fig, width='stretch', config={'responsive': True})
    else:
        st.info("üìä M√©triques globales non disponibles")
except Exception as e:
    st.error(f"Erreur m√©triques: {str(e)[:100]}")

# Info colonnes optimis√©e
col_count = len(df.columns)
if col_count > 8:
    col_info = f"**{col_count} colonnes** : {', '.join(list(df.columns)[:6])}... +{col_count-6}"
else:
    col_info = f"**{col_count} colonnes** : {', '.join(list(df.columns))}"
st.info(col_info)

# Onglets avec gestion stable
tabs = st.tabs(["üìà Qualit√©", "üî¨ Variables", "üîó Relations", "üåê Corr√©lations", "üìÑ Aper√ßu", "üóëÔ∏è Nettoyage"])

# Onglet 1: Qualit√© des donn√©es
with tabs[0]:
    st.markdown('<div class="tab-content">', unsafe_allow_html=True)
    st.subheader("üìä Qualit√© des Donn√©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        try:
            missing_fig = plot_missing_values_overview(df)
            if missing_fig:
                st.plotly_chart(missing_fig, width='stretch', config={'responsive': True})
            else:
                st.success("‚úÖ Aucune valeur manquante")
        except Exception as e:
            st.error("Erreur valeurs manquantes")
            logger.error(f"Missing values plot: {e}")
    
    with col2:
        try:
            cardinality_fig = plot_cardinality_overview(df, column_types)
            if cardinality_fig:
                st.plotly_chart(cardinality_fig, width='stretch', config={'responsive': True})
            else:
                st.info("üìä Cardinalit√© uniforme")
        except Exception as e:
            st.error("Erreur cardinalit√©")
            logger.error(f"Cardinality plot: {e}")
    
    st.markdown('</div>', unsafe_allow_html=True)

# Onglet 2: Analyse univari√©e
with tabs[1]:
    st.markdown('<div class="tab-content">', unsafe_allow_html=True)
    st.subheader("üîç Analyse Univari√©e")
    
    available_columns = list(df.columns)
    if not available_columns:
        st.warning("Aucune colonne disponible")
    else:
        # S√©lecteur stable avec √©tat persistant
        if not st.session_state.selected_univar_col or st.session_state.selected_univar_col not in available_columns:
            st.session_state.selected_univar_col = available_columns[0]
        
        selected_col = st.selectbox(
            "Variable √† analyser :",
            options=available_columns,
            index=available_columns.index(st.session_state.selected_univar_col),
            format_func=lambda x: f"{x} ({'Num√©rique' if x in column_types.get('numeric', []) else 'Cat√©gorielle'})",
            key="univar_selector"
        )
        
        # Mise √† jour de l'√©tat seulement si n√©cessaire
        if selected_col != st.session_state.selected_univar_col:
            st.session_state.selected_univar_col = selected_col
        
        if selected_col:
            try:
                sample_df = DataSampler.get_sample(df)
                col_data = sample_df[selected_col].dropna()
                
                if col_data.empty:
                    st.warning(f"Aucune donn√©e valide pour **{selected_col}**")
                else:
                    if selected_col in column_types.get('numeric', []):
                        # Statistiques num√©riques
                        stats_cols = st.columns(4)
                        with stats_cols[0]:
                            st.metric("Moyenne", f"{col_data.mean():.3f}")
                        with stats_cols[1]:
                            st.metric("M√©diane", f"{col_data.median():.3f}")
                        with stats_cols[2]:
                            st.metric("√âcart-type", f"{col_data.std():.3f}")
                        with stats_cols[3]:
                            st.metric("Uniques", f"{col_data.nunique():,}")
                        
                        # Graphique
                        with st.spinner("üìä G√©n√©ration du graphique..."):
                            fig = plot_distribution(col_data, selected_col)
                            if fig:
                                st.plotly_chart(fig, width='stretch', config={'responsive': True})
                            else:
                                st.info("Graphique non disponible")
                    else:
                        # Variable cat√©gorielle
                        value_counts = col_data.value_counts().head(20)
                        
                        if not value_counts.empty:
                            col_chart, col_table = st.columns([2, 1])
                            
                            with col_table:
                                df_display = value_counts.reset_index()
                                df_display.columns = ['Valeur', 'Count']
                                st.dataframe(df_display, height=400, width='stretch')
                            
                            with col_chart:
                                import plotly.express as px
                                fig = px.bar(
                                    x=value_counts.index.astype(str),
                                    y=value_counts.values,
                                    labels={'x': selected_col, 'y': 'Fr√©quence'},
                                    title=f"Distribution de {selected_col}"
                                )
                                fig.update_layout(template="plotly_white", height=400)
                                st.plotly_chart(fig, width='stretch', config={'responsive': True})
                        else:
                            st.info("Aucune donn√©e √† afficher")
                            
            except Exception as e:
                st.error(f"Erreur analyse de {selected_col}")
                logger.error(f"Univariate analysis error for {selected_col}: {e}")

    st.markdown('</div>', unsafe_allow_html=True)

# Onglet 3: Relations bivari√©es
with tabs[2]:
    st.markdown('<div class="tab-content">', unsafe_allow_html=True)
    st.subheader("üîó Relations entre Variables")
    
    available_columns = list(df.columns)
    
    if len(available_columns) >= 2:
        # √âtats persistants pour s√©lections
        if not st.session_state.selected_bivar_col1 or st.session_state.selected_bivar_col1 not in available_columns:
            st.session_state.selected_bivar_col1 = available_columns[0]
        
        if not st.session_state.selected_bivar_col2 or st.session_state.selected_bivar_col2 not in available_columns:
            st.session_state.selected_bivar_col2 = available_columns[1] if len(available_columns) > 1 else available_columns[0]
        
        col1, col2 = st.columns(2)
        
        with col1:
            var1 = st.selectbox(
                "Variable 1",
                options=available_columns,
                index=available_columns.index(st.session_state.selected_bivar_col1),
                key="bivar_var1"
            )
            if var1 != st.session_state.selected_bivar_col1:
                st.session_state.selected_bivar_col1 = var1
        
        with col2:
            var2 = st.selectbox(
                "Variable 2",
                options=available_columns,
                index=available_columns.index(st.session_state.selected_bivar_col2),
                key="bivar_var2"
            )
            if var2 != st.session_state.selected_bivar_col2:
                st.session_state.selected_bivar_col2 = var2
        
        if var1 != var2:
            try:
                type1 = 'numeric' if var1 in column_types.get('numeric', []) else 'categorical'
                type2 = 'numeric' if var2 in column_types.get('numeric', []) else 'categorical'
                
                sample_df = DataSampler.get_sample(df, Config.MAX_BIVARIATE_SAMPLE)
                
                if not sample_df[[var1, var2]].empty:
                    with st.spinner("üìä G√©n√©ration de l'analyse bivari√©e..."):
                        biv_fig = plot_bivariate_analysis(sample_df, var1, var2, type1, type2)
                        if biv_fig:
                            st.plotly_chart(biv_fig, width='stretch', config={'responsive': True})
                        else:
                            st.info("Graphique non disponible pour cette combinaison")
                else:
                    st.warning("Donn√©es insuffisantes")
                    
            except Exception as e:
                st.error("Erreur analyse bivari√©e")
                logger.error(f"Bivariate analysis error: {e}")
        else:
            st.warning("S√©lectionnez deux variables diff√©rentes")
    else:
        st.warning("Au moins 2 colonnes n√©cessaires")

    st.markdown('</div>', unsafe_allow_html=True)

# Onglet 4: Corr√©lations - VERSION CORRIG√âE
with tabs[3]:
    st.markdown('<div class="tab-content">', unsafe_allow_html=True)
    st.subheader("üåê Matrice de Corr√©lations")
    
    # Options de configuration simplifi√©es
    col_config1, col_config2 = st.columns(2)
    
    with col_config1:
        # S√©lecteur de colonnes num√©riques seulement
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        if numeric_cols:
            target_col = st.selectbox(
                "Variable cible (optionnelle)", 
                options=[None] + numeric_cols,
                key="corr_target_select"
            )
        else:
            st.warning("Aucune variable num√©rique disponible")
            target_col = None
    
    with col_config2:
        # Option pour forcer le mode simple
        use_simple_mode = st.checkbox("Mode simple (recommand√©)", value=True, key="simple_mode")
    
    if st.button("üîÑ G√©n√©rer la matrice", type="primary", key="generate_corr"):
        with st.spinner("üìä Calcul des corr√©lations..."):
            try:
                # √âchantillonner pour les performances
                sample_df = DataSampler.get_sample(df, max_rows=3000)  # R√©duit la taille
                
                if use_simple_mode:
                    # Utiliser la version simple
                    corr_fig, used_cols = create_simple_correlation_heatmap(sample_df, max_cols=15)
                else:
                    # Utiliser la version compl√®te
                    corr_fig, used_cols = plot_correlation_heatmap(
                        sample_df, 
                        target_column=target_col,
                        task_type="classification" if target_col else None
                    )
                
                if corr_fig:
                    st.plotly_chart(corr_fig, width='stretch', config={'responsive': True})
                    st.success(f"‚úÖ Matrice g√©n√©r√©e avec {len(used_cols)} variables")
                else:
                    st.warning("‚ùå Impossible de g√©n√©rer la matrice")
                    st.info("Essayez avec le mode simple activ√©")
                    
            except Exception as e:
                st.error("Erreur lors du calcul des corr√©lations")
                logger.error(f"Correlation error: {e}")
                
                # Fallback direct avec Plotly Express
                try:
                    st.info("Tentative avec m√©thode alternative...")
                    numeric_cols = sample_df.select_dtypes(include=[np.number]).columns
                    if len(numeric_cols) > 1:
                        corr_matrix = sample_df[numeric_cols].corr()
                        fig = px.imshow(corr_matrix, text_auto=".2f", aspect="auto")
                        st.plotly_chart(fig, width='stretch')
                    else:
                        st.info("Pas assez de variables num√©riques")
                except Exception as fallback_e:
                    st.error("√âchec de toutes les m√©thodes")

    st.markdown('</div>', unsafe_allow_html=True)

# Onglet 5: Aper√ßu donn√©es brutes
with tabs[4]:
    st.markdown('<div class="tab-content">', unsafe_allow_html=True)
    st.subheader("üìÑ Aper√ßu des Donn√©es Brutes")
    
    try:
        # Utiliser df_raw si disponible, sinon df
        raw_df = st.session_state.get('df_raw', df)
        total_rows = compute_if_dask(raw_df.shape[0])
        
        # Configuration de l'aper√ßu
        col_config1, col_config2, col_config3 = st.columns(3)
        
        with col_config1:
            preview_size = st.slider(
                "Nombre de lignes √† afficher",
                min_value=10,
                max_value=min(500, total_rows),
                value=min(Config.MAX_PREVIEW_ROWS, total_rows),
                key="preview_size_slider"
            )
        
        with col_config2:
            show_from_start = st.radio("Affichage", ["D√©but", "√âchantillon"], key="preview_type")
        
        with col_config3:
            show_dtypes = st.checkbox("Afficher les types", value=False, key="show_dtypes")
        
        # Pr√©paration des donn√©es √† afficher
        if show_from_start == "D√©but":
            display_df = compute_if_dask(raw_df.head(preview_size))
        else:
            display_df = DataSampler.get_sample(raw_df, preview_size)
        
        # Gestion des colonnes avec beaucoup de texte
        display_df_truncated = display_df.copy()
        for col in display_df_truncated.select_dtypes(include=['object']).columns:
            display_df_truncated[col] = display_df_truncated[col].astype(str).apply(
                lambda x: x[:50] + "..." if len(str(x)) > 50 else x
            )
        
        # Affichage principal
        st.dataframe(
            display_df_truncated,
            height=400,
            width='stretch'
        )
        
        # Affichage des types de donn√©es si demand√©
        if show_dtypes:
            with st.expander("üìä Types de donn√©es des colonnes"):
                dtypes_info = []
                for col in display_df.columns:
                    dtype = str(display_df[col].dtype)
                    non_null_count = display_df[col].count()
                    total_count = len(display_df[col])
                    null_percentage = ((total_count - non_null_count) / total_count * 100) if total_count > 0 else 0
                    
                    dtypes_info.append({
                        'Colonne': col,
                        'Type': dtype,
                        'Non-null': non_null_count,
                        'Null (%)': f"{null_percentage:.1f}%"
                    })
                
                dtypes_df = pd.DataFrame(dtypes_info)
                st.dataframe(dtypes_df, width='stretch')
        
        # Informations compl√©mentaires
        info_col1, info_col2, info_col3 = st.columns(3)
        
        with info_col1:
            st.caption(f"üìä {len(display_df)} lignes affich√©es sur {total_rows:,} total")
        
        with info_col2:
            st.caption(f"üìã {len(display_df.columns)} colonnes")
        
        with info_col3:
            if len(display_df) > 0 and len(display_df.columns) > 0:
                missing_pct = (display_df.isnull().sum().sum() / (len(display_df) * len(display_df.columns))) * 100
                st.caption(f"üï≥Ô∏è {missing_pct:.1f}% valeurs manquantes")
            else:
                st.caption("üï≥Ô∏è Donn√©es insuffisantes")
        
        # Bouton de t√©l√©chargement de l'√©chantillon
        st.markdown("---")
        col_download1, col_download2 = st.columns([3, 1])
        
        with col_download2:
            if st.button("üíæ T√©l√©charger l'√©chantillon", key="download_sample"):
                try:
                    csv = display_df.to_csv(index=False)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f"echantillon_donnees_{time.strftime('%Y%m%d_%H%M')}.csv",
                        mime="text/csv",
                        key="download_csv"
                    )
                except Exception as download_error:
                    st.error("‚ùå Erreur lors de la pr√©paration du t√©l√©chargement")
                    logger.error(f"Download error: {download_error}")
    
    except Exception as e:
        st.error("‚ùå Erreur lors de l'affichage de l'aper√ßu des donn√©es")
        logger.error(f"Data preview error: {e}")
        
        # Fallback simple
        try:
            st.info("üîÑ Tentative de chargement simplifi√©...")
            fallback_df = compute_if_dask(df.head(50))
            st.dataframe(fallback_df, height=300, width='stretch')
            st.caption(f"üìä Affichage de secours: 50 premi√®res lignes sur {compute_if_dask(df.shape[0]):,} total")
        except Exception as fallback_error:
            st.error("üö® Impossible d'afficher les donn√©es")
            logger.error(f"Fallback preview also failed: {fallback_error}")

    st.markdown('</div>', unsafe_allow_html=True)

# Onglet 6: Nettoyage des donn√©es 
with tabs[5]:
    st.markdown('<div class="tab-content">', unsafe_allow_html=True)
    st.subheader("üóëÔ∏è Nettoyage des Donn√©es")
    
    st.markdown("### üîç D√©tection des colonnes inutiles")
    
    # Choix du mode : automatique ou manuel
    mode = st.radio(
        "Mode de s√©lection des colonnes √† supprimer :",
        options=["Automatique", "Manuelle"],
        horizontal=True
    )
    
    cols_to_remove = []

    # --- Mode automatique ---
    if mode == "Automatique":
        col_detect, col_action = st.columns([2, 1])
        with col_detect:
            if st.button("üîé Analyser les colonnes inutiles", key="analyze_useless"):
                with st.spinner("Analyse en cours..."):
                    try:
                        useless_cols = detect_useless_columns(df, threshold_missing=0.7)
                        st.session_state.useless_candidates = useless_cols
                        
                        if useless_cols:
                            st.success(f"‚úÖ {len(useless_cols)} colonne(s) potentiellement inutile(s) d√©tect√©e(s)")
                            st.write(
                                "**Colonnes d√©tect√©es:**",
                                ", ".join(useless_cols[:5]) + ("..." if len(useless_cols) > 5 else "")
                            )
                            cols_to_remove = useless_cols
                        else:
                            st.info("üéâ Aucune colonne inutile d√©tect√©e")
                    except Exception as e:
                        st.error("‚ùå Erreur lors de l'analyse")
                        logger.error(f"Useless columns detection error: {e}")
        
        with col_action:
            if st.session_state.useless_candidates:
                if st.button("üóëÔ∏è Supprimer les colonnes inutiles", type="primary"):
                    try:
                        valid_cols = [col for col in st.session_state.useless_candidates if col in df.columns]
                        if valid_cols:
                            if is_dask_dataframe(df):
                                new_df = df.drop(columns=valid_cols).persist()
                            else:
                                new_df = df.drop(columns=valid_cols)
                            st.session_state.df = new_df
                            st.session_state.useless_candidates = []
                            st.session_state.column_types = None
                            st.session_state.dashboard_version += 1
                            st.success(f"‚úÖ {len(valid_cols)} colonne(s) supprim√©e(s)")
                            st.rerun()
                        else:
                            st.warning("‚ö†Ô∏è Aucune colonne valide √† supprimer")
                    except Exception as e:
                        st.error("‚ùå Erreur lors de la suppression")
                        logger.error(f"Column removal error: {e}")

    # --- Mode manuel ---
    else:
        all_cols = df.columns.tolist()
        cols_to_remove = st.multiselect(
            "S√©lectionnez les colonnes √† supprimer",
            options=all_cols,
            default=[]
        )
        if cols_to_remove:
            if st.button("üóëÔ∏è Supprimer les colonnes s√©lectionn√©es", type="primary"):
                try:
                    valid_cols = [col for col in cols_to_remove if col in df.columns]
                    if valid_cols:
                        if is_dask_dataframe(df):
                            new_df = df.drop(columns=valid_cols).persist()
                        else:
                            new_df = df.drop(columns=valid_cols)
                        st.session_state.df = new_df
                        st.session_state.column_types = None
                        st.session_state.dashboard_version += 1
                        st.success(f"‚úÖ {len(valid_cols)} colonne(s) supprim√©e(s)")
                        st.rerun()
                    else:
                        st.warning("‚ö†Ô∏è Aucune colonne valide √† supprimer")
                except Exception as e:
                    st.error("‚ùå Erreur lors de la suppression")
                    logger.error(f"Manual column removal error: {e}")

    st.markdown("---")
    st.markdown("### ‚úèÔ∏è Renommage des colonnes")
    
    col_rename1, col_rename2 = st.columns(2)
    
    with col_rename1:
        if df.columns.tolist():
            col_to_rename = st.selectbox(
                "Colonne √† renommer",
                options=df.columns.tolist(),
                key="rename_select"
            )
        else:
            col_to_rename = None
            st.warning("Aucune colonne disponible")
    
    with col_rename2:
        new_name = st.text_input(
            "Nouveau nom",
            placeholder="Nouveau nom de colonne",
            key="rename_input"
        )
    
    col_add, col_clear = st.columns(2)
    
    with col_add:
        if st.button("‚ûï Ajouter au plan de renommage", key="add_rename"):
            if col_to_rename and new_name and DataValidator.is_valid_column_name(new_name):
                if new_name not in df.columns:
                    if (col_to_rename, new_name) not in st.session_state.rename_list:
                        st.session_state.rename_list.append((col_to_rename, new_name))
                        st.success(f"‚úÖ {col_to_rename} ‚Üí {new_name} ajout√©")
                    else:
                        st.warning("‚ö†Ô∏è Ce renommage est d√©j√† planifi√©")
                else:
                    st.error("‚ùå Ce nom de colonne existe d√©j√†")
            else:
                st.error("‚ùå Nom invalide ou vide")
    
    with col_clear:
        if st.button("üóëÔ∏è Vider la liste", key="clear_renames"):
            st.session_state.rename_list = []
            st.success("‚úÖ Liste vid√©e")
    
    # Affichage des renommages planifi√©s
    if st.session_state.rename_list:
        st.markdown("**üìã Renommages planifi√©s:**")
        rename_df = pd.DataFrame(st.session_state.rename_list, columns=["Ancien nom", "Nouveau nom"])
        st.dataframe(rename_df, width='stretch')
        
        if st.button("‚úÖ Appliquer tous les renommages", type="primary", key="apply_renames"):
            try:
                rename_dict = dict(st.session_state.rename_list)
                valid_renames = {old: new for old, new in rename_dict.items() if old in df.columns}
                
                if valid_renames:
                    if is_dask_dataframe(df):
                        new_df = df.rename(columns=valid_renames).persist()
                    else:
                        new_df = df.rename(columns=valid_renames)
                    st.session_state.df = new_df
                    st.session_state.rename_list = []
                    st.session_state.column_types = None
                    st.session_state.dashboard_version += 1
                    st.success(f"‚úÖ {len(valid_renames)} colonne(s) renomm√©e(s)")
                    st.rerun()
                else:
                    st.warning("‚ö†Ô∏è Aucun renommage valide √† appliquer")
            except Exception as e:
                st.error("‚ùå Erreur lors du renommage")
                logger.error(f"Rename error: {e}")

    st.markdown("---")
    st.markdown("### üõ†Ô∏è Actions de maintenance")
    
    col_maint1, col_maint2 = st.columns(2)
    
    with col_maint1:
        if st.button("üßπ Nettoyer la m√©moire", key="cleanup_mem"):
            try:
                cleanup_memory()
                st.success("‚úÖ M√©moire nettoy√©e")
            except Exception as e:
                st.error("‚ùå Erreur de nettoyage")
    
    with col_maint2:
        if st.button("üîÑ Rafra√Æchir l'analyse", key="refresh_analysis"):
            try:
                st.session_state.column_types = None
                st.cache_data.clear()
                st.success("‚úÖ Analyse rafra√Æchie")
                st.rerun()
            except Exception as e:
                st.error("‚ùå Erreur de rafra√Æchissement")

    st.markdown('</div>', unsafe_allow_html=True)

# Footer final avec informations syst√®me
st.markdown("---")
footer_cols = st.columns(4)

with footer_cols[0]:
    try:
        n_rows = compute_if_dask(df.shape[0])
        n_cols = df.shape[1]
        st.caption(f"üìä {n_rows:,} √ó {n_cols}")
    except:
        st.caption("üìä Donn√©es non disponibles")

with footer_cols[1]:
    try:
        if not is_dask_dataframe(df):
            memory_mb = compute_if_dask(df.memory_usage(deep=True).sum()) / (1024**2)
            st.caption(f"üíæ {memory_mb:.1f} MB")
        else:
            st.caption(f"üíæ {df.npartitions} partitions")
    except:
        st.caption("üíæ N/A")

with footer_cols[2]:
    try:
        sys_mem = psutil.virtual_memory().percent
        status = "üî¥" if sys_mem > Config.MEMORY_CRITICAL else "üü°" if sys_mem > Config.MEMORY_WARNING else "üü¢"
        st.caption(f"{status} {sys_mem:.0f}% RAM")
    except:
        st.caption("üîß RAM: N/A")

with footer_cols[3]:
    st.caption(f"üïí {time.strftime('%H:%M:%S')}")

# Nettoyage final
gc.collect()