import streamlit as st
import pandas as pd
import time
import psutil
import os
from typing import Dict, List, Any
from functools import wraps
import numpy as np

# Imports des modules ML
from ml.catalog import MODEL_CATALOG
from utils.data_analysis import get_target_and_task, detect_imbalance, auto_detect_column_types
from ml.training import train_models
from utils.logging_config import get_logger

# Configuration
logger = get_logger(__name__)
st.set_page_config(page_title="Configuration ML", page_icon="‚öôÔ∏è", layout="wide")

# Configuration production
def setup_ml_config_environment():
    """Configuration pour l'environnement de production ML"""
    if 'ml_config_setup_done' not in st.session_state:
        st.session_state.ml_config_setup_done = True
        if os.getenv('STREAMLIT_ENV') == 'production':
            hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            .stDeployButton {display:none;}
            footer {visibility: hidden;}
            #stDecoration {display:none;}
            .stAlert > div {padding: 0.5rem;}
            .stProgress .st-bo {background-color: #3498db;}
            </style>
            """
            st.markdown(hide_streamlit_style, unsafe_allow_html=True)

setup_ml_config_environment()

# D√©corateur de monitoring
def monitor_ml_operation(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            elapsed = time.time() - start_time
            if elapsed > 10:
                logger.warning(f"ML operation {func.__name__} took {elapsed:.2f}s")
            return result
        except Exception as e:
            logger.error(f"ML operation {func.__name__} failed: {e}")
            raise
    return wrapper

# Validation des features pour clustering
def validate_clustering_features(df: pd.DataFrame, features: List[str]) -> Dict[str, Any]:
    """Valide que les features sont adapt√©es au clustering avec suggestions"""
    validation = {
        "is_valid": True,
        "issues": [],
        "warnings": [],
        "valid_features": [],
        "suggested_features": []
    }
    
    try:
        # Analyse des corr√©lations pour suggestions
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 1:
            corr_matrix = df[numeric_cols].corr().abs()
            low_corr_cols = [col for col in numeric_cols if col in features and corr_matrix[col].mean() < 0.7]
            validation["suggested_features"] = low_corr_cols[:10]  # Limite √† 10

        for feature in features:
            if feature not in df.columns:
                validation["issues"].append(f"Colonne '{feature}' non trouv√©e")
                continue
                
            if df[feature].std() == 0:
                validation["warnings"].append(f"'{feature}' est constante")
                continue
                
            missing_ratio = df[feature].isnull().mean()
            if missing_ratio > 0.5:
                validation["warnings"].append(f"'{feature}' a {missing_ratio:.1%} de valeurs manquantes")
                continue
                
            if df[feature].nunique() == 1:
                validation["warnings"].append(f"'{feature}' n'a qu'une seule valeur unique")
                continue
                
            validation["valid_features"].append(feature)
        
        validation["is_valid"] = len(validation["valid_features"]) >= 2
        if not validation["is_valid"]:
            validation["issues"].append("Minimum 2 variables num√©riques requises")
        
    except Exception as e:
        validation["is_valid"] = False
        validation["issues"].append(f"Erreur validation: {str(e)}")
    
    return validation

# Estimation temps d'entra√Ænement
def estimate_training_time(df: pd.DataFrame, n_models: int, task_type: str, 
                         optimize_hp: bool, n_features: int, use_smote: bool = False) -> int:
    """Estime le temps d'entra√Ænement de fa√ßon r√©aliste"""
    try:
        n_samples = len(df)
        base_complexity = (n_samples * n_features) / 1000
        time_multipliers = {
            'clustering': 1.2,
            'classification': 1.5 if use_smote else 1.3,
            'regression': 1.4
        }
        time_multiplier = time_multipliers.get(task_type, 1.5)
        if optimize_hp:
            time_multiplier *= 3.5
        estimated_seconds = base_complexity * n_models * time_multiplier
        return max(30, min(int(estimated_seconds), 3600))
    except Exception as e:
        logger.warning(f"Erreur estimation temps: {e}")
        return 60

# V√©rification ressources syst√®me
def check_system_resources(df: pd.DataFrame, n_models: int) -> Dict[str, Any]:
    """V√©rifie si le syst√®me a assez de ressources"""
    check_result = {
        "has_enough_resources": True,
        "issues": [],
        "warnings": [],
        "available_memory_mb": 0,
        "estimated_needed_mb": 0
    }
    
    try:
        df_memory = df.memory_usage(deep=True).sum() / (1024**2)
        estimated_needed = df_memory * n_models * 3
        available_memory = psutil.virtual_memory().available / (1024**2)
        check_result["available_memory_mb"] = available_memory
        check_result["estimated_needed_mb"] = estimated_needed
        
        if estimated_needed > available_memory:
            check_result["has_enough_resources"] = False
            check_result["issues"].append(f"M√©moire insuffisante: {estimated_needed:.0f}MB requis, {available_memory:.0f}MB disponible")
        elif estimated_needed > available_memory * 0.7:
            check_result["warnings"].append(f"M√©moire limite: {estimated_needed:.0f}MB requis, {available_memory:.0f}MB disponible")
        
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > 90:
            check_result["warnings"].append(f"CPU √©lev√©: {cpu_percent:.1f}%")
            
    except Exception as e:
        check_result["warnings"].append("V√©rification ressources √©chou√©e")
        logger.warning(f"Erreur v√©rification ressources: {e}")
    
    return check_result

# Validation DataFrame
@st.cache_data(ttl=300, max_entries=3)
def validate_dataframe_for_ml(df: pd.DataFrame) -> Dict[str, Any]:
    """Valide le DataFrame pour ML"""
    validation = {
        "is_valid": True,
        "issues": [],
        "warnings": [],
        "min_rows_required": 50,
        "min_cols_required": 2,
        "stats": {}
    }
    
    try:
        if df is None or df.empty:
            validation["is_valid"] = False
            validation["issues"].append("DataFrame vide ou non charg√©")
            return validation
        
        n_rows, n_cols = df.shape
        validation["stats"] = {"n_rows": n_rows, "n_cols": n_cols}
        
        if n_rows < validation["min_rows_required"]:
            validation["is_valid"] = False
            validation["issues"].append(f"Insuffisant: {n_rows} lignes (minimum: {validation['min_rows_required']})")
        
        if n_cols < validation["min_cols_required"]:
            validation["is_valid"] = False
            validation["issues"].append(f"Insuffisant: {n_cols} colonnes (minimum: {validation['min_cols_required']})")
        
        missing_ratio = df.isnull().mean().max()
        if missing_ratio > 0.95:
            validation["is_valid"] = False
            validation["issues"].append(f"Trop de valeurs manquantes: {missing_ratio:.1%}")
        elif missing_ratio > 0.7:
            validation["warnings"].append(f"Beaucoup de valeurs manquantes: {missing_ratio:.1%}")
        
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            constant_cols = [col for col in numeric_cols if df[col].std() == 0]
            if len(constant_cols) == len(numeric_cols):
                validation["warnings"].append("Toutes les colonnes num√©riques sont constantes")
        
        memory_usage = df.memory_usage(deep=True).sum() / (1024**2)
        validation["stats"]["memory_mb"] = memory_usage
        if memory_usage > 1000:
            validation["warnings"].append(f"Dataset volumineux: {memory_usage:.1f} MB")
            
    except Exception as e:
        validation["is_valid"] = False
        validation["issues"].append(f"Erreur validation: {str(e)}")
        logger.error(f"DataFrame validation error: {e}")
    
    return validation

# Initialisation √©tat
def initialize_ml_config_state():
    """Initialise l'√©tat de configuration ML"""
    defaults = {
        'target_column_for_ml_config': None,
        'feature_list_for_ml_config': [],
        'preprocessing_choices': {
            'numeric_imputation': 'mean',
            'categorical_imputation': 'most_frequent',
            'use_smote': False,
            'remove_constant_cols': True,
            'remove_identifier_cols': True,
            'scale_features': True,
            'pca_preprocessing': False
        },
        'selected_models_for_training': [],
        'test_split_for_ml_config': 20,
        'optimize_hp_for_ml_config': False,
        'task_type': 'classification',
        'ml_training_in_progress': False,
        'ml_last_training_time': None,
        'ml_error_count': 0,
        'ml_session_id': int(time.time()),
        'current_step': 1,
        'previous_task_type': None
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

@monitor_ml_operation
def safe_get_task_type(df: pd.DataFrame, target_column: str) -> Dict[str, Any]:
    """D√©tection s√©curis√©e du type de t√¢che"""
    try:
        if not target_column or target_column not in df.columns:
            return {"task_type": "unknown", "n_classes": 0, "error": "Colonne cible invalide"}
        
        if df[target_column].nunique() == len(df):
            return {"task_type": "unknown", "n_classes": 0, "error": "Variable cible est un identifiant"}
        
        result_dict = get_target_and_task(df, target_column)
        task_type = result_dict.get("task", "unknown")
        target_type = result_dict.get("target_type", "unknown")
        
        n_classes = 0
        if task_type == "classification":
            n_classes = df[target_column].nunique()
            if n_classes > 100:
                return {"task_type": "unknown", "n_classes": n_classes, "error": f"Trop de classes ({n_classes})"}
        
        return {"task_type": task_type, "target_type": target_type, "n_classes": n_classes, "error": None}
    except Exception as e:
        logger.error(f"Task type detection failed: {e}")
        return {"task_type": "unknown", "n_classes": 0, "error": str(e)}

def get_task_specific_models(task_type: str) -> List[str]:
    """Retourne les mod√®les disponibles pour une t√¢che"""
    try:
        return list(MODEL_CATALOG.get(task_type, {}).keys())
    except Exception as e:
        logger.error(f"Error getting models for {task_type}: {e}")
        return []

def get_default_models_for_task(task_type: str) -> List[str]:
    """Retourne les mod√®les par d√©faut pour une t√¢che"""
    default_models = {
        'classification': ['RandomForest', 'XGBoost', 'LogisticRegression'],
        'regression': ['RandomForest', 'XGBoost', 'LinearRegression'],
        'clustering': ['KMeans', 'DBSCAN', 'GaussianMixture']
    }
    available_models = get_task_specific_models(task_type)
    return [model for model in default_models.get(task_type, []) if model in available_models]

# Interface principale
st.title("‚öôÔ∏è Configuration de l'Exp√©rimentation ML")
st.markdown("Configurez votre analyse en 4 √©tapes simples et lancez l'entra√Ænement des mod√®les.")

# V√©rification des donn√©es
if 'df' not in st.session_state or st.session_state.df is None:
    st.error("üìä Aucun dataset charg√©")
    st.info("Chargez un dataset depuis la page d'accueil.")
    if st.button("üè† Retour √† l'accueil"):
        st.switch_page("app.py")
    st.stop()

df = st.session_state.df

# Validation DataFrame
validation_result = validate_dataframe_for_ml(df)
if not validation_result["is_valid"]:
    st.error("‚ùå Dataset non compatible avec l'analyse ML")
    with st.expander("üîç D√©tails des probl√®mes", expanded=True):
        for issue in validation_result["issues"]:
            st.error(f"‚Ä¢ {issue}")
        st.info("**Crit√®res requis**:\n- Minimum 50 lignes\n- Minimum 2 colonnes\n- Moins de 95% de valeurs manquantes")
    if st.button("üîÑ Rev√©rifier"):
        st.rerun()
    st.stop()

if validation_result["warnings"]:
    with st.expander("‚ö†Ô∏è Avertissements qualit√© donn√©es", expanded=False):
        for warning in validation_result["warnings"]:
            st.warning(f"‚Ä¢ {warning}")

# Initialisation √©tat
initialize_ml_config_state()

# M√©triques dataset
st.markdown("### üìä Aper√ßu du Dataset")
col1, col2, col3, col4, col5 = st.columns(5)
with col1:
    st.metric("üìè Lignes", f"{validation_result['stats']['n_rows']:,}")
with col2:
    st.metric("üìã Colonnes", validation_result["stats"]["n_cols"])
with col3:
    memory_mb = validation_result["stats"].get("memory_mb", 0)
    st.metric("üíæ M√©moire", f"{memory_mb:.1f} MB" if memory_mb > 0 else "N/A")
with col4:
    missing_pct = df.isnull().mean().mean() * 100
    st.metric("üï≥Ô∏è Manquant", f"{missing_pct:.1f}%")
with col5:
    sys_memory = psutil.virtual_memory().percent
    color = "üü¢" if sys_memory < 70 else "üü°" if sys_memory < 85 else "üî¥"
    st.metric(f"{color} RAM Sys", f"{sys_memory:.0f}%")

st.markdown("---")

# Navigation par √©tapes
steps = ["üéØ Cible", "üîß Pr√©process", "ü§ñ Mod√®les", "üöÄ Lancement"]
col_nav1, col_nav2, col_nav3 = st.columns([1, 2, 1])
with col_nav2:
    selected_step = st.radio("√âtapes", steps, index=st.session_state.current_step - 1, horizontal=True, key="step_selector")
st.session_state.current_step = steps.index(selected_step) + 1

# √âtape 1: Configuration cible
if st.session_state.current_step == 1:
    st.header("üéØ Configuration de la T√¢che et Cible")
    
    task_options = ["Classification Supervis√©e", "R√©gression Supervis√©e", "Clustering Non Supervis√©"]
    task_descriptions = {
        "Classification Supervis√©e": "Pr√©dire des cat√©gories (ex: spam/non-spam)",
        "R√©gression Supervis√©e": "Pr√©dire des valeurs num√©riques (ex: prix, score)", 
        "Clustering Non Supervis√©": "D√©couvrir des groupes naturels dans les donn√©es"
    }
    
    current_task_idx = {'classification': 0, 'regression': 1, 'clustering': 2}.get(st.session_state.task_type, 0)
    task_selection = st.selectbox(
        "Type de probl√®me ML",
        options=task_options,
        index=current_task_idx,
        key="ml_task_selection",
        help="S√©lectionnez le type d'apprentissage adapt√© √† vos donn√©es"
    )
    st.info(f"**{task_selection}** - {task_descriptions[task_selection]}")
    
    selected_task_type = {
        "Classification Supervis√©e": "classification",
        "R√©gression Supervis√©e": "regression",
        "Clustering Non Supervis√©": "clustering"
    }[task_selection]
    
    if st.session_state.previous_task_type != selected_task_type:
        st.session_state.target_column_for_ml_config = None
        st.session_state.feature_list_for_ml_config = []
        st.session_state.preprocessing_choices['use_smote'] = False
        st.session_state.previous_task_type = selected_task_type
        st.session_state.task_type = selected_task_type
        st.rerun()
    else:
        st.session_state.task_type = selected_task_type
    
    if selected_task_type in ['classification', 'regression']:
        st.subheader("üéØ Variable Cible (Y)")
        available_targets = (
            [col for col in df.columns if df[col].nunique() <= 50 or not pd.api.types.is_numeric_dtype(df[col])]
            if selected_task_type == 'classification' else
            [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col]) and df[col].nunique() > 10]
        )
        
        if not available_targets:
            st.error("‚ùå Aucune variable cible appropri√©e trouv√©e")
            st.info("Classification: ‚â§50 valeurs uniques\nR√©gression: num√©rique, >10 valeurs uniques")
        else:
            available_targets = [None] + available_targets
            target_idx = available_targets.index(st.session_state.target_column_for_ml_config) if st.session_state.target_column_for_ml_config in available_targets else 0
            target_column = st.selectbox(
                "Variable √† pr√©dire",
                options=available_targets,
                index=target_idx,
                key="ml_target_selector",
                help="Variable que le mod√®le apprendra √† pr√©dire"
            )
            
            if target_column != st.session_state.target_column_for_ml_config:
                st.session_state.target_column_for_ml_config = target_column
                st.session_state.feature_list_for_ml_config = []
            
            if target_column:
                task_info = safe_get_task_type(df, target_column)
                if task_info["error"]:
                    st.error(f"‚ùå Erreur: {task_info['error']}")
                    st.info("Action: S√©lectionnez une autre colonne ou v√©rifiez les donn√©es.")
                else:
                    if selected_task_type == "classification":
                        st.success(f"‚úÖ **Classification** ({task_info['n_classes']} classes)")
                        class_dist = df[target_column].value_counts()
                        if len(class_dist) <= 10:
                            st.bar_chart(class_dist)
                            st.caption(f"Distribution des classes")
                        imbalance_info = detect_imbalance(df, target_column)
                        if imbalance_info.get("is_imbalanced", False):
                            st.warning(f"‚ö†Ô∏è D√©s√©quilibre (ratio: {imbalance_info.get('imbalance_ratio', 'N/A'):.2f})")
                    else:
                        st.success("‚úÖ **R√©gression**")
                        target_stats = df[target_column].describe()
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Moyenne", f"{target_stats['mean']:.3f}")
                        with col2:
                            st.metric("M√©diane", f"{target_stats['50%']:.3f}")
                        with col3:
                            st.metric("√âcart-type", f"{target_stats['std']:.3f}")
                        with col4:
                            st.metric("Plage", f"{target_stats['max'] - target_stats['min']:.3f}")
        
        st.subheader("üìä Variables Explicatives (X)")
        all_features = [col for col in df.columns if col != target_column] if target_column else list(df.columns)
        
        if all_features:
            recommend_features = st.checkbox(
                "S√©lection automatique des features",
                value=len(st.session_state.feature_list_for_ml_config) == 0,
                help="S√©lectionne automatiquement les variables pertinentes"
            )
            
            if recommend_features and target_column:
                with st.spinner("ü§ñ Analyse des features..."):
                    column_types = auto_detect_column_types(df)
                    recommended_features = column_types.get('numeric', []) + [
                        col for col in column_types.get('categorical', []) if df[col].nunique() <= 20
                    ]
                    recommended_features = [col for col in recommended_features if col != target_column and col in all_features][:25]
                    st.session_state.feature_list_for_ml_config = recommended_features
                    st.success(f"‚úÖ {len(recommended_features)} features s√©lectionn√©es")
            else:
                selected_features = st.multiselect(
                    "Variables d'entr√©e",
                    options=all_features,
                    default=st.session_state.feature_list_for_ml_config,
                    key="ml_features_selector",
                    help="Variables utilis√©es pour la pr√©diction"
                )
                st.session_state.feature_list_for_ml_config = selected_features
            
            if st.session_state.feature_list_for_ml_config:
                st.success(f"‚úÖ {len(st.session_state.feature_list_for_ml_config)} features s√©lectionn√©es")
                st.caption(f"üìã {', '.join(st.session_state.feature_list_for_ml_config[:10])}{' ...' if len(st.session_state.feature_list_for_ml_config) > 10 else ''}")
                if len(st.session_state.feature_list_for_ml_config) > 30:
                    st.warning("‚ö†Ô∏è Nombre √©lev√© de features - risque de surapprentissage")
                    st.info("Action: R√©duisez le nombre de features ou activez PCA.")
            else:
                st.warning("‚ö†Ô∏è Aucune feature s√©lectionn√©e")
                st.info("Action: S√©lectionnez au moins une variable.")
        else:
            st.error("‚ùå Aucune feature disponible")
            st.info("Action: V√©rifiez votre dataset.")
    
    else:  # Clustering
        st.session_state.target_column_for_ml_config = None
        st.success("‚úÖ **Clustering Non Supervis√©**")
        st.info("üîç Le mod√®le identifiera des groupes naturels dans les donn√©es.")
        
        all_numeric_features = df.select_dtypes(include=['number']).columns.tolist()
        if not all_numeric_features:
            st.error("‚ùå Aucune variable num√©rique pour le clustering")
            st.info("Action: Ajoutez des variables num√©riques au dataset.")
        else:
            st.subheader("üìä Variables pour le Clustering")
            auto_cluster_features = st.checkbox(
                "S√©lection automatique",
                value=len(st.session_state.feature_list_for_ml_config) == 0,
                help="S√©lectionne les variables num√©riques adapt√©es"
            )
            
            if auto_cluster_features:
                validation_result = validate_clustering_features(df, all_numeric_features)
                st.session_state.feature_list_for_ml_config = validation_result["valid_features"]
                if validation_result["suggested_features"]:
                    st.info(f"üí° Suggestion: {', '.join(validation_result['suggested_features'][:5])}")
                if validation_result["warnings"]:
                    with st.expander("‚ö†Ô∏è Avertissements", expanded=True):
                        for warning in validation_result["warnings"]:
                            st.warning(f"‚Ä¢ {warning}")
                st.success(f"‚úÖ {len(st.session_state.feature_list_for_ml_config)} variables s√©lectionn√©es")
            else:
                clustering_features = st.multiselect(
                    "Variables pour clustering",
                    options=all_numeric_features,
                    default=st.session_state.feature_list_for_ml_config or all_numeric_features[:10],
                    key="clustering_features_selector",
                    help="Variables num√©riques pour identifier les clusters"
                )
                validation_result = validate_clustering_features(df, clustering_features)
                st.session_state.feature_list_for_ml_config = validation_result["valid_features"]
                if validation_result["suggested_features"]:
                    st.info(f"üí° Suggestion: {', '.join(validation_result['suggested_features'][:5])}")
                if validation_result["warnings"]:
                    with st.expander("‚ö†Ô∏è Avertissements", expanded=True):
                        for warning in validation_result["warnings"]:
                            st.warning(f"‚Ä¢ {warning}")
            
            if st.session_state.feature_list_for_ml_config:
                st.success(f"‚úÖ {len(st.session_state.feature_list_for_ml_config)} variables s√©lectionn√©es")
                if len(st.session_state.feature_list_for_ml_config) < 2:
                    st.warning("‚ö†Ô∏è Minimum 2 variables pour clustering")
                    st.info("Action: Ajoutez des variables num√©riques.")
                elif len(st.session_state.feature_list_for_ml_config) > 15:
                    st.warning("‚ö†Ô∏è Nombre √©lev√© de variables - risque de mal√©diction dimensionnelle")
                    st.info("Action: Activez PCA ou r√©duisez les variables.")
                with st.expander("üìà Aper√ßu statistiques", expanded=False):
                    st.dataframe(df[st.session_state.feature_list_for_ml_config].describe().style.format("{:.3f}"), width='stretch')
            else:
                st.warning("‚ö†Ô∏è Aucune variable s√©lectionn√©e")
                st.info("Action: S√©lectionnez des variables num√©riques.")

# √âtape 2: Pr√©traitement
elif st.session_state.current_step == 2:
    st.header("üîß Configuration du Pr√©traitement")
    task_type = st.session_state.get('task_type', 'classification')
    
    st.info(f"**Pipeline pour {task_type.upper()}**: Transformations appliqu√©es s√©par√©ment sur train/validation pour √©viter le data leakage.")
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üß© Valeurs Manquantes")
        st.session_state.preprocessing_choices['numeric_imputation'] = st.selectbox(
            "Variables num√©riques",
            options=['mean', 'median', 'constant', 'knn'],
            index=['mean', 'median', 'constant', 'knn'].index(st.session_state.preprocessing_choices.get('numeric_imputation', 'mean')),
            key='numeric_imputation_selector',
            help="mean=moyenne, median=m√©diane, constant=0, knn=k-voisins"
        )
        st.session_state.preprocessing_choices['categorical_imputation'] = st.selectbox(
            "Variables cat√©gorielles",
            options=['most_frequent', 'constant'],
            index=['most_frequent', 'constant'].index(st.session_state.preprocessing_choices.get('categorical_imputation', 'most_frequent')),
            key='categorical_imputation_selector',
            help="most_frequent=mode, constant='missing'"
        )
        
        st.subheader("üßπ Nettoyage")
        st.session_state.preprocessing_choices['remove_constant_cols'] = st.checkbox(
            "Supprimer colonnes constantes",
            value=st.session_state.preprocessing_choices.get('remove_constant_cols', True),
            key="remove_constant_checkbox",
            help="√âlimine variables sans variance"
        )
        st.session_state.preprocessing_choices['remove_identifier_cols'] = st.checkbox(
            "Supprimer colonnes identifiantes",
            value=st.session_state.preprocessing_choices.get('remove_identifier_cols', True),
            key="remove_id_checkbox",
            help="√âlimine variables avec valeurs uniques (ID)"
        )
    
    with col2:
        st.subheader("üìè Normalisation")
        scale_help = {
            'classification': "Recommand√© pour SVM, KNN, r√©seaux de neurones",
            'regression': "Recommand√© pour la plupart des algorithmes",
            'clustering': "ESSENTIEL pour le clustering (KMeans, DBSCAN)"
        }
        st.session_state.preprocessing_choices['scale_features'] = st.checkbox(
            "Normaliser les features",
            value=st.session_state.preprocessing_choices.get('scale_features', True),
            key="scale_features_checkbox",
            help=scale_help.get(task_type, "Recommand√©")
        )
        if task_type == 'clustering' and not st.session_state.preprocessing_choices.get('scale_features', True):
            st.error("‚ùå Normalisation critique pour le clustering!")
            st.info("Action: Activez la normalisation pour de meilleurs r√©sultats.")
        
        if task_type == 'classification':
            st.subheader("‚öñÔ∏è D√©s√©quilibre")
            if st.session_state.target_column_for_ml_config:
                imbalance_info = detect_imbalance(df, st.session_state.target_column_for_ml_config)
                if imbalance_info.get("is_imbalanced", False):
                    st.warning(f"üìâ D√©s√©quilibre (ratio: {imbalance_info.get('imbalance_ratio', 'N/A'):.2f})")
                    st.session_state.preprocessing_choices['use_smote'] = st.checkbox(
                        "Activer SMOTE",
                        value=st.session_state.preprocessing_choices.get('use_smote', True),
                        key="smote_checkbox",
                        help="√âquilibre les classes minoritaires"
                    )
                else:
                    st.success("‚úÖ Classes √©quilibr√©es")
                    st.session_state.preprocessing_choices['use_smote'] = st.checkbox(
                        "SMOTE (optionnel)",
                        value=False,
                        key="smote_optional_checkbox"
                    )
            else:
                st.info("üîí Variable cible requise")
                st.session_state.preprocessing_choices['use_smote'] = False
        
        elif task_type == 'clustering':
            st.subheader("üîç Clustering")
            st.session_state.preprocessing_choices['pca_preprocessing'] = st.checkbox(
                "R√©duction dimension (PCA)",
                value=st.session_state.preprocessing_choices.get('pca_preprocessing', False),
                help="R√©duit le bruit pour donn√©es haute dimension"
            )

# √âtape 3: Mod√®les
elif st.session_state.current_step == 3:
    st.header("ü§ñ S√©lection des Mod√®les")
    task_type = st.session_state.get('task_type', 'classification')
    available_models = get_task_specific_models(task_type)
    
    if not available_models:
        st.error(f"‚ùå Aucun mod√®le disponible pour '{task_type}'")
        st.info("Action: V√©rifiez le catalogue de mod√®les.")
        st.stop()
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.subheader("üéØ Mod√®les")
        if not st.session_state.selected_models_for_training:
            st.session_state.selected_models_for_training = get_default_models_for_task(task_type)
        
        selected_models = st.multiselect(
            f"Mod√®les {task_type}",
            options=available_models,
            default=st.session_state.selected_models_for_training,
            key="models_multiselect",
            help="Mod√®les √† entra√Æner et comparer"
        )
        st.session_state.selected_models_for_training = selected_models
        
        if selected_models:
            st.success(f"‚úÖ {len(selected_models)} mod√®les s√©lectionn√©s")
            with st.expander("üìã D√©tails des mod√®les", expanded=False):
                for model_name in selected_models:
                    model_config = MODEL_CATALOG[task_type].get(model_name, {})
                    st.write(f"**{model_name}**")
                    st.caption(f"‚Ä¢ {model_config.get('description', 'N/A')}")
                    if task_type == 'clustering':
                        if model_name == 'KMeans':
                            st.caption("üí° Clusters sph√©riques, taille similaire")
                        elif model_name == 'DBSCAN':
                            st.caption("üí° Robustes au bruit, forme arbitraire")
                        elif model_name == 'GaussianMixture':
                            st.caption("üí° Probabiliste, taille variable")
        else:
            st.warning("‚ö†Ô∏è Aucun mod√®le s√©lectionn√©")
            st.info("Action: S√©lectionnez au moins un mod√®le.")
    
    with col2:
        st.subheader("‚öôÔ∏è Configuration")
        if task_type != 'clustering':
            test_split = st.slider(
                "Jeu de test (%)",
                min_value=10,
                max_value=40,
                value=st.session_state.get('test_split_for_ml_config', 20),
                step=5,
                key="test_split_slider",
                help="Donn√©es r√©serv√©es pour l'√©valuation"
            )
            st.session_state.test_split_for_ml_config = test_split
            st.caption(f"üìä {test_split}% test, {100-test_split}% entra√Ænement")
        else:
            st.info("üîç Clustering: 100% des donn√©es utilis√©es")
            st.session_state.test_split_for_ml_config = 0
        
        optimize_hp = st.checkbox(
            "Optimisation hyperparam√®tres",
            value=st.session_state.get('optimize_hp_for_ml_config', False),
            key="optimize_hp_checkbox",
            help="Recherche des meilleurs param√®tres (plus long)"
        )
        st.session_state.optimize_hp_for_ml_config = optimize_hp
        
        if optimize_hp:
            st.warning("‚è∞ Temps d'entra√Ænement +3-5x")
            optimization_method = st.selectbox(
                "M√©thode",
                options=['Silhouette Score', 'Davies-Bouldin'] if task_type == 'clustering' else ['GridSearch', 'RandomSearch'],
                index=0,
                key="optimization_method_selector",
                help="Silhouette=qualit√© clusters, GridSearch=exhaustif, RandomSearch=rapide"
            )
            st.session_state.optimization_method = optimization_method
        
        n_features = len(st.session_state.feature_list_for_ml_config)
        estimated_seconds = estimate_training_time(df, len(selected_models), task_type, optimize_hp, n_features, st.session_state.preprocessing_choices.get('use_smote', False))
        st.info(f"‚è±Ô∏è Temps estim√©: {max(1, estimated_seconds // 60)} minute(s)")
        
        if selected_models:
            resource_check = check_system_resources(df, len(selected_models))
            if not resource_check["has_enough_resources"]:
                st.error("‚ùå Ressources insuffisantes")
                for issue in resource_check["issues"]:
                    st.error(f"‚Ä¢ {issue}")
                st.info("Action: R√©duisez le nombre de mod√®les ou lib√©rez de la m√©moire.")
            elif resource_check["warnings"]:
                st.warning("‚ö†Ô∏è Ressources limites")
                for warning in resource_check["warnings"]:
                    st.warning(f"‚Ä¢ {warning}")

# √âtape 4: Lancement
elif st.session_state.current_step == 4:
    st.header("üöÄ Lancement de l'Exp√©rimentation")
    task_type = st.session_state.get('task_type', 'classification')
    
    config_issues = []
    if task_type in ['classification', 'regression'] and not st.session_state.target_column_for_ml_config:
        config_issues.append("Variable cible non d√©finie")
    if not st.session_state.feature_list_for_ml_config:
        config_issues.append("Aucune variable explicative s√©lectionn√©e")
    elif len(st.session_state.feature_list_for_ml_config) < 2 and task_type == 'clustering':
        config_issues.append("Minimum 2 variables pour clustering")
    if not st.session_state.selected_models_for_training:
        config_issues.append("Aucun mod√®le s√©lectionn√©")
    
    if task_type == 'clustering' and not st.session_state.preprocessing_choices.get('scale_features', True):
        config_issues.append("Normalisation requise pour clustering")
    if len(st.session_state.feature_list_for_ml_config) > 30:
        config_issues.append("Trop de features - risque de surapprentissage")
    
    resource_check = check_system_resources(df, len(st.session_state.selected_models_for_training))
    config_issues.extend(resource_check["issues"])
    
    with st.expander("üìã R√©capitulatif", expanded=True):
        if config_issues:
            st.error("‚ùå Configuration incompl√®te:")
            for issue in config_issues:
                st.error(f"‚Ä¢ {issue}")
                st.info("Action: Revenez aux √©tapes pr√©c√©dentes pour corriger.")
        else:
            st.success("‚úÖ Configuration valide")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**üìä Donn√©es**")
            st.write(f"‚Ä¢ Type: {task_type.upper()}")
            if task_type != 'clustering':
                st.write(f"‚Ä¢ Cible: `{st.session_state.target_column_for_ml_config}`")
            st.write(f"‚Ä¢ Features: {len(st.session_state.feature_list_for_ml_config)}")
            if task_type != 'clustering':
                st.write(f"‚Ä¢ Test: {st.session_state.test_split_for_ml_config}%")
            else:
                st.write("‚Ä¢ Test: 0% (clustering)")
        with col2:
            st.markdown("**ü§ñ Mod√®les**")
            st.write(f"‚Ä¢ Mod√®les: {len(st.session_state.selected_models_for_training)}")
            st.write(f"‚Ä¢ Optimisation: {'‚úÖ' if st.session_state.optimize_hp_for_ml_config else '‚ùå'}")
            if task_type == 'classification':
                st.write(f"‚Ä¢ SMOTE: {'‚úÖ' if st.session_state.preprocessing_choices.get('use_smote') else '‚ùå'}")
            st.write(f"‚Ä¢ Normalisation: {'‚úÖ' if st.session_state.preprocessing_choices.get('scale_features') else '‚ùå'}")
    
    col_launch, col_reset = st.columns([2, 1])
    with col_launch:
        launch_disabled = len(config_issues) > 0 or st.session_state.get('ml_training_in_progress', False)
        if st.button("üöÄ Lancer", type="primary", width='stretch', disabled=launch_disabled):
            st.session_state.ml_training_in_progress = True
            st.session_state.ml_last_training_time = time.time()
            
            training_config = {
                'df': df,
                'target_column': st.session_state.target_column_for_ml_config,
                'model_names': st.session_state.selected_models_for_training,
                'task_type': task_type,
                'test_size': st.session_state.test_split_for_ml_config / 100 if task_type != 'clustering' else 0.0,
                'optimize': st.session_state.optimize_hp_for_ml_config,
                'feature_list': st.session_state.feature_list_for_ml_config,
                'use_smote': st.session_state.preprocessing_choices.get('use_smote', False),
                'preprocessing_choices': st.session_state.preprocessing_choices
            }
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            results_container = st.empty()
            
            try:
                status_text.text("üìä Pr√©paration des donn√©es...")
                progress_bar.progress(10)
                time.sleep(0.5)
                
                n_models = len(st.session_state.selected_models_for_training)
                results = []
                for i, model_name in enumerate(st.session_state.selected_models_for_training):
                    status_text.text(f"üîß Entra√Ænement {i+1}/{n_models}: {model_name}")
                    progress_bar.progress(10 + int((i / n_models) * 80))
                    model_config = training_config.copy()
                    model_config['model_names'] = [model_name]
                    try:
                        model_results = train_models(**model_config)
                        results.extend(model_results)
                    except Exception as e:
                        logger.error(f"Erreur entra√Ænement {model_name}: {e}")
                        results.append({
                            "model_name": model_name,
                            "metrics": {"error": str(e)},
                            "success": False,
                            "training_time": 0,
                            "X_sample": None,
                            "y_test": None,
                            "labels": None,
                            "feature_names": st.session_state.feature_list_for_ml_config
                        })
                    time.sleep(0.5)
                
                status_text.text("‚úÖ Finalisation...")
                progress_bar.progress(95)
                time.sleep(0.5)
                
                elapsed_time = time.time() - st.session_state.ml_last_training_time
                status_text.text(f"‚úÖ Termin√© en {elapsed_time:.1f}s")
                progress_bar.progress(100)
                
                st.session_state.ml_results = results
                st.session_state.ml_training_in_progress = False
                st.session_state.ml_error_count = 0
                
                successful_models = [r for r in results if r.get('success', False) and not r.get('metrics', {}).get('error')]
                with results_container.container():
                    st.success(f"‚úÖ {len(successful_models)}/{len(results)} mod√®les r√©ussis")
                    if successful_models:
                        key_metric = 'silhouette_score' if task_type == 'clustering' else 'r2' if task_type == 'regression' else 'accuracy'
                        best_model = max(successful_models, key=lambda x: x.get('metrics', {}).get(key_metric, -999))
                        best_score = best_model.get('metrics', {}).get(key_metric, 0)
                        st.info(f"üèÜ Meilleur mod√®le: **{best_model['model_name']}** ({key_metric.title()}: {best_score:.3f})")
                    if st.button("üìà Voir r√©sultats", width='stretch'):
                        st.switch_page("pages/3_üìà_√âvaluation_du_Mod√®le.py")
                
            except Exception as e:
                st.session_state.ml_training_in_progress = False
                st.session_state.ml_error_count = st.session_state.get('ml_error_count', 0) + 1
                status_text.text("‚ùå √âchec")
                progress_bar.progress(0)
                st.error(f"‚ùå Erreur: {str(e)[:200]}")
                st.info("Action: V√©rifiez la configuration ou contactez le support.")
                logger.error(f"Training failed: {e}", exc_info=True)
    
    with col_reset:
        if st.button("üîÑ Reset", width='stretch'):
            ml_keys_to_reset = [
                'target_column_for_ml_config', 'feature_list_for_ml_config',
                'selected_models_for_training', 'ml_results', 'task_type',
                'previous_task_type'
            ]
            for key in ml_keys_to_reset:
                if key in st.session_state:
                    del st.session_state[key]
            st.session_state.current_step = 1
            st.success("Configuration r√©initialis√©e")
            st.rerun()

# Footer
st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1:
    progress = (st.session_state.current_step / len(steps)) * 100
    st.caption(f"üìä √âtape {st.session_state.current_step}/{len(steps)} ({progress:.0f}%)")
with col2:
    st.caption(f"üéØ {st.session_state.get('task_type', 'Non d√©fini').upper()}")
with col3:
    st.caption(f"‚è∞ {time.strftime('%H:%M:%S')}")

# Navigation
col_prev, col_next = st.columns(2)
with col_prev:
    if st.session_state.current_step > 1:
        if st.button("‚óÄÔ∏è Pr√©c√©dent", width='stretch'):
            st.session_state.current_step -= 1
            st.rerun()
with col_next:
    if st.session_state.current_step < 4:
        if st.button("Suivant ‚ñ∂Ô∏è", width='stretch', type="primary"):
            if st.session_state.current_step == 1:
                if st.session_state.task_type in ['classification', 'regression'] and not st.session_state.target_column_for_ml_config:
                    st.error("Veuillez s√©lectionner une variable cible")
                elif not st.session_state.feature_list_for_ml_config:
                    st.error("Veuillez s√©lectionner au moins une variable")
                else:
                    st.session_state.current_step += 1
                    st.rerun()
            else:
                st.session_state.current_step += 1
                st.rerun()

# Debug
if os.getenv("DEBUG_MODE", "false").lower() == "true":
    with st.expander("üîç Debug", expanded=False):
        st.json({
            "current_step": st.session_state.current_step,
            "task_type": st.session_state.get('task_type'),
            "target_column": st.session_state.get('target_column_for_ml_config'),
            "num_features": len(st.session_state.get('feature_list_for_ml_config', [])),
            "num_models": len(st.session_state.get('selected_models_for_training', [])),
            "test_split": st.session_state.get('test_split_for_ml_config'),
            "training_in_progress": st.session_state.get('ml_training_in_progress', False),
            "error_count": st.session_state.get('ml_error_count', 0)
        })