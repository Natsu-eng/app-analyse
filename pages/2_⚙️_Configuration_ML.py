import streamlit as st
import pandas as pd
import time
import psutil
import os
from typing import Dict, List, Any
from functools import wraps

# Imports des modules ML
from ml.catalog import MODEL_CATALOG
from utils.data_analysis import get_target_and_task, detect_imbalance, auto_detect_column_types
from ml.training import train_models
from utils.logging_config import get_logger

# Configuration
logger = get_logger(__name__)
st.set_page_config(page_title="Configuration ML", page_icon="‚öôÔ∏è", layout="wide")

# Configuration production
def setup_ml_config_environment():
    """Configuration pour l'environnement de production ML"""
    if 'ml_config_setup_done' not in st.session_state:
        st.session_state.ml_config_setup_done = True
        
        if os.getenv('STREAMLIT_ENV') == 'production':
            hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            .stDeployButton {display:none;}
            footer {visibility: hidden;}
            #stDecoration {display:none;}
            .stAlert > div {padding: 0.5rem;}
            </style>
            """
            st.markdown(hide_streamlit_style, unsafe_allow_html=True)

setup_ml_config_environment()

# D√©corateur de monitoring
def monitor_ml_operation(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            elapsed = time.time() - start_time
            if elapsed > 10:
                logger.warning(f"ML operation {func.__name__} took {elapsed:.2f}s")
            return result
        except Exception as e:
            logger.error(f"ML operation {func.__name__} failed: {e}")
            raise
    return wrapper

# NOUVELLE FONCTION : Validation des features pour clustering
def validate_clustering_features(df: pd.DataFrame, features: List[str]) -> Dict[str, Any]:
    """Valide que les features sont adapt√©es au clustering"""
    validation = {
        "is_valid": True,
        "issues": [],
        "warnings": [],
        "valid_features": []
    }
    
    try:
        for feature in features:
            if feature not in df.columns:
                validation["issues"].append(f"Colonne '{feature}' non trouv√©e")
                continue
                
            # V√©rifier si constante
            if df[feature].std() == 0:
                validation["warnings"].append(f"'{feature}' est constante")
                continue
                
            # V√©rifier valeurs manquantes
            missing_ratio = df[feature].isnull().mean()
            if missing_ratio > 0.5:
                validation["warnings"].append(f"'{feature}' a {missing_ratio:.1%} de valeurs manquantes")
                continue
                
            # V√©rifier variance acceptable
            if df[feature].nunique() == 1:
                validation["warnings"].append(f"'{feature}' n'a qu'une seule valeur unique")
                continue
                
            validation["valid_features"].append(feature)
        
        validation["is_valid"] = len(validation["valid_features"]) >= 2
        
    except Exception as e:
        validation["is_valid"] = False
        validation["issues"].append(f"Erreur validation: {str(e)}")
    
    return validation

# NOUVELLE FONCTION : Estimation temps plus pr√©cise
def estimate_training_time(df: pd.DataFrame, n_models: int, task_type: str, 
                          optimize_hp: bool, n_features: int, use_smote: bool = False) -> int:
    """Estime le temps d'entra√Ænement de fa√ßon plus r√©aliste"""
    try:
        n_samples = len(df)
        
        # Complexit√© de base bas√©e sur taille donn√©es
        base_complexity = (n_samples * n_features) / 1000
        
        # Multiplicateurs selon les param√®tres
        time_multipliers = {
            'clustering': 1.2,
            'classification': 1.5 if use_smote else 1.3,
            'regression': 1.4
        }
        
        if optimize_hp:
            time_multipliers = {k: v * 3.5 for k, v in time_multipliers.items()}
        
        time_multiplier = time_multipliers.get(task_type, 1.5)
        
        # Estimation en secondes
        estimated_seconds = base_complexity * n_models * time_multiplier
        
        # Bornes raisonnables
        min_seconds = 30  # Minimum 30 secondes
        max_seconds = 3600  # Maximum 1 heure
        
        estimated_seconds = max(min_seconds, min(estimated_seconds, max_seconds))
        
        return int(estimated_seconds)
        
    except Exception as e:
        logger.warning(f"Erreur estimation temps: {e}")
        return 60  # Valeur par d√©faut

# NOUVELLE FONCTION : V√©rification ressources syst√®me
def check_system_resources(df: pd.DataFrame, n_models: int) -> Dict[str, Any]:
    """V√©rifie si le syst√®me a assez de ressources pour l'entra√Ænement"""
    check_result = {
        "has_enough_resources": True,
        "issues": [],
        "warnings": [],
        "available_memory_mb": 0,
        "estimated_needed_mb": 0
    }
    
    try:
        # Estimation m√©moire n√©cessaire
        df_memory = df.memory_usage(deep=True).sum() / (1024**2)
        estimated_needed = df_memory * n_models * 3  # Buffer 3x
        
        # M√©moire disponible
        available_memory = psutil.virtual_memory().available / (1024**2)
        
        check_result["available_memory_mb"] = available_memory
        check_result["estimated_needed_mb"] = estimated_needed
        
        # V√©rifications
        if estimated_needed > available_memory:
            check_result["has_enough_resources"] = False
            check_result["issues"].append(
                f"M√©moire insuffisante (n√©cessaire: {estimated_needed:.0f}MB, disponible: {available_memory:.0f}MB)"
            )
        elif estimated_needed > available_memory * 0.7:
            check_result["warnings"].append(
                f"M√©moire limite (n√©cessaire: {estimated_needed:.0f}MB, disponible: {available_memory:.0f}MB)"
            )
        
        # V√©rification CPU
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > 90:
            check_result["warnings"].append(f"CPU √©lev√©: {cpu_percent:.1f}%")
            
    except Exception as e:
        logger.warning(f"Erreur v√©rification ressources: {e}")
        check_result["warnings"].append("Impossible de v√©rifier les ressources syst√®me")
    
    return check_result

# Validation s√©curis√©e du DataFrame
@st.cache_data(ttl=300, max_entries=3)
def validate_dataframe_for_ml(df: pd.DataFrame) -> Dict[str, Any]:
    """Valide le DataFrame pour l'analyse ML avec crit√®res stricts"""
    validation = {
        "is_valid": True,
        "issues": [],
        "warnings": [],
        "min_rows_required": 50,
        "min_cols_required": 2,
        "stats": {}
    }
    
    try:
        if df is None or df.empty:
            validation["is_valid"] = False
            validation["issues"].append("DataFrame vide ou non charg√©")
            return validation
        
        n_rows, n_cols = df.shape
        validation["stats"] = {"n_rows": n_rows, "n_cols": n_cols}
        
        # V√©rifications dimensionnelles
        if n_rows < validation["min_rows_required"]:
            validation["is_valid"] = False
            validation["issues"].append(f"Insuffisant: {n_rows} lignes (minimum: {validation['min_rows_required']})")
        
        if n_cols < validation["min_cols_required"]:
            validation["is_valid"] = False
            validation["issues"].append(f"Insuffisant: {n_cols} colonnes (minimum: {validation['min_cols_required']})")
        
        # Analyse qualit√© des donn√©es
        try:
            missing_ratio = df.isnull().mean().max()
            if missing_ratio > 0.95:
                validation["is_valid"] = False
                validation["issues"].append(f"Trop de valeurs manquantes: {missing_ratio:.1%}")
            elif missing_ratio > 0.7:
                validation["warnings"].append(f"Beaucoup de valeurs manquantes: {missing_ratio:.1%}")
            
            # V√©rification variance
            numeric_cols = df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                low_variance_cols = []
                for col in numeric_cols:
                    if df[col].std() == 0:
                        low_variance_cols.append(col)
                
                if len(low_variance_cols) == len(numeric_cols):
                    validation["warnings"].append("Toutes les colonnes num√©riques sont constantes")
            
        except Exception as e:
            validation["warnings"].append(f"Analyse qualit√© √©chou√©e: {str(e)[:50]}")
        
        # V√©rification m√©moire
        try:
            memory_usage = df.memory_usage(deep=True).sum() / (1024**2)
            validation["stats"]["memory_mb"] = memory_usage
            if memory_usage > 1000:  # 1GB
                validation["warnings"].append(f"Dataset volumineux: {memory_usage:.1f} MB")
        except:
            validation["warnings"].append("Calcul m√©moire impossible")
        
    except Exception as e:
        validation["is_valid"] = False
        validation["issues"].append(f"Erreur validation: {str(e)}")
        logger.error(f"DataFrame validation error: {e}")
    
    return validation

# Initialisation robuste de l'√©tat 
def initialize_ml_config_state():
    """Initialise l'√©tat de configuration ML de fa√ßon robuste"""
    defaults = {
        'target_column_for_ml_config': None,
        'feature_list_for_ml_config': [],
        'preprocessing_choices': {
            'numeric_imputation': 'mean',
            'categorical_imputation': 'most_frequent',
            'use_smote': False,
            'remove_constant_cols': True,
            'remove_identifier_cols': True,
            'scale_features': True
        },
        'selected_models_for_training': [],
        'test_split_for_ml_config': 20,
        'optimize_hp_for_ml_config': False,
        'task_type': 'classification',
        'ml_training_in_progress': False,
        'ml_last_training_time': None,
        'ml_error_count': 0,
        'ml_session_id': int(time.time()),
        'current_step': 1,
        'previous_task_type': None  # NOUVEAU : pour d√©tection changement
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

@monitor_ml_operation
def safe_get_task_type(df: pd.DataFrame, target_column: str) -> Dict[str, Any]:
    """Version s√©curis√©e de la d√©tection du type de t√¢che - AM√âLIOR√âE"""
    try:
        if not target_column or target_column not in df.columns:
            return {"task_type": "unknown", "n_classes": 0, "error": "Colonne cible invalide"}
        
        # V√©rifier si c'est un identifiant (valeurs uniques)
        if df[target_column].nunique() == len(df):
            return {
                "task_type": "unknown", 
                "n_classes": df[target_column].nunique(),
                "error": "Variable cible a des valeurs uniques pour chaque ligne (probable identifiant)"
            }
        
        # Appel s√©curis√© √† get_target_and_task
        result_dict = get_target_and_task(df, target_column)
        
        if not isinstance(result_dict, dict):
            return {"task_type": "unknown", "n_classes": 0, "error": "R√©sultat invalide"}
        
        task_type = result_dict.get("task", "unknown")
        target_type = result_dict.get("target_type", "unknown")
        
        # Calcul s√©curis√© du nombre de classes
        n_classes = 0
        try:
            if task_type == "classification":
                n_classes = df[target_column].nunique()
                if n_classes > 100:
                    return {
                        "task_type": "unknown",
                        "n_classes": n_classes,
                        "error": f"Trop de classes ({n_classes}) pour une classification standard"
                    }
        except Exception as e:
            logger.debug(f"Class count calculation failed: {e}")
        
        return {
            "task_type": task_type,
            "target_type": target_type,
            "n_classes": n_classes,
            "error": None
        }
        
    except Exception as e:
        logger.error(f"Task type detection failed: {e}")
        return {"task_type": "unknown", "n_classes": 0, "error": str(e)}

def get_task_specific_models(task_type: str) -> List[str]:
    """Retourne les mod√®les disponibles pour un type de t√¢che sp√©cifique"""
    try:
        if task_type == 'clustering':
            return list(MODEL_CATALOG.get('clustering', {}).keys())
        elif task_type == 'regression':
            return list(MODEL_CATALOG.get('regression', {}).keys())
        else:  # classification par d√©faut
            return list(MODEL_CATALOG.get('classification', {}).keys())
    except Exception as e:
        logger.error(f"Error getting models for {task_type}: {e}")
        return []

def get_default_models_for_task(task_type: str) -> List[str]:
    """Retourne les mod√®les par d√©faut pour chaque type de t√¢che"""
    default_models = {
        'classification': ['RandomForest', 'XGBoost', 'LogisticRegression'],
        'regression': ['RandomForest', 'XGBoost', 'LinearRegression'],
        'clustering': ['KMeans', 'DBSCAN', 'GaussianMixture']
    }
    available_models = get_task_specific_models(task_type)
    return [model for model in default_models.get(task_type, []) if model in available_models]

# Interface principale
st.title("‚öôÔ∏è Configuration D√©taill√©e de l'Exp√©riences")

# V√©rification des donn√©es avec validation stricte
if 'df' not in st.session_state or st.session_state.df is None:
    st.error("üìä Aucun dataset charg√©")
    st.info("Chargez d'abord un dataset depuis la page d'accueil pour configurer l'exp√©rience ML.")
    if st.button("üè† Retour √† l'accueil"):
        st.switch_page("app.py")
    st.stop()

df = st.session_state.df

# Validation stricte du DataFrame
validation_result = validate_dataframe_for_ml(df)
if not validation_result["is_valid"]:
    st.error("‚ùå Dataset non compatible avec l'analyse ML")
    with st.expander("üîç D√©tails des probl√®mes", expanded=True):
        for issue in validation_result["issues"]:
            st.error(f"‚Ä¢ {issue}")
    
    st.info("""
    **Crit√®res requis pour l'analyse ML:**
    - Minimum 50 lignes de donn√©es
    - Minimum 2 colonnes
    - Moins de 95% de valeurs manquantes par colonne
    """)
    
    if st.button("üîÑ Rev√©rifier"):
        st.rerun()
    st.stop()

# Avertissements non-bloquants
if validation_result["warnings"]:
    with st.expander("‚ö†Ô∏è Avertissements qualit√© donn√©es", expanded=False):
        for warning in validation_result["warnings"]:
            st.warning(f"‚Ä¢ {warning}")

# Initialisation de l'√©tat
initialize_ml_config_state()

# M√©triques du dataset avec design am√©lior√©
st.markdown("### üìä Aper√ßu du Dataset")
col1, col2, col3, col4, col5 = st.columns(5)

with col1:
    n_rows = validation_result["stats"]["n_rows"]
    st.metric("üìè Lignes", f"{n_rows:,}")

with col2:
    n_cols = validation_result["stats"]["n_cols"]
    st.metric("üìã Colonnes", f"{n_cols}")

with col3:
    memory_mb = validation_result["stats"].get("memory_mb", 0)
    if memory_mb > 0:
        st.metric("üíæ M√©moire", f"{memory_mb:.1f} MB")
    else:
        st.metric("üíæ M√©moire", "N/A")

with col4:
    missing_pct = df.isnull().mean().mean() * 100
    st.metric("üï≥Ô∏è Manquant", f"{missing_pct:.1f}%")

with col5:
    try:
        sys_memory = psutil.virtual_memory().percent
        color = "üî¥" if sys_memory > 85 else "üü°" if sys_memory > 70 else "üü¢"
        st.metric(f"{color} RAM Sys", f"{sys_memory:.0f}%")
    except:
        st.metric("üîß RAM Sys", "N/A")

st.markdown("---")

# Navigation par √©tapes avec √©tat persistant
steps = ["üéØ Cible", "üîß Pr√©process", "ü§ñ Mod√®les", "üöÄ Lancement"]
selected_step = st.radio("√âtapes de configuration", steps, index=st.session_state.current_step - 1, horizontal=True)
st.session_state.current_step = steps.index(selected_step) + 1

# √âtape 1: Configuration de la cible
if st.session_state.current_step == 1:
    st.header("üéØ Configuration de la T√¢che et Cible")
    
    # S√©lection du type de t√¢che avec √©tat stable
    task_options = ["Classification Supervis√©e", "R√©gression Supervis√©e", "Clustering Non Supervis√©"]
    task_descriptions = {
        "Classification Supervis√©e": "Pr√©dire des cat√©gories (ex: spam/non-spam)",
        "R√©gression Supervis√©e": "Pr√©dire des valeurs num√©riques (ex: prix, score)", 
        "Clustering Non Supervis√©": "D√©couvrir des groupes naturels dans les donn√©es"
    }
    
    # D√©terminer l'index initial bas√© sur l'√©tat actuel
    if st.session_state.task_type == 'clustering':
        current_task_idx = 2
    elif st.session_state.task_type == 'regression':
        current_task_idx = 1
    else:
        current_task_idx = 0
    
    task_selection = st.selectbox(
        "Type de probl√®me ML √† r√©soudre",
        options=task_options,
        index=current_task_idx,
        key="ml_task_selection_stable",
        help="S√©lectionnez le type d'apprentissage adapt√© √† vos donn√©es"
    )
    
    # Afficher la description
    st.info(f"**{task_selection}** - {task_descriptions[task_selection]}")
    
    # Mapper la s√©lection au type de t√¢che
    task_mapping = {
        "Classification Supervis√©e": "classification",
        "R√©gression Supervis√©e": "regression", 
        "Clustering Non Supervis√©": "clustering"
    }
    
    selected_task_type = task_mapping[task_selection]
    
    # NOUVEAU : Reset automatique quand le type de t√¢che change
    if st.session_state.previous_task_type != selected_task_type:
        st.info("üîÑ Type de t√¢che modifi√© - r√©initialisation des s√©lections...")
        
        # Reset des configurations qui ne sont plus valides
        if selected_task_type == 'clustering':
            st.session_state.target_column_for_ml_config = None
            st.session_state.preprocessing_choices['use_smote'] = False
            # Reset features pour clustering
            st.session_state.feature_list_for_ml_config = []
        elif selected_task_type in ['classification', 'regression']:
            # Reset des s√©lections inappropri√©es
            if st.session_state.target_column_for_ml_config and st.session_state.target_column_for_ml_config not in df.columns:
                st.session_state.target_column_for_ml_config = None
        
        st.session_state.previous_task_type = selected_task_type
        st.session_state.task_type = selected_task_type
        st.rerun()
    else:
        st.session_state.task_type = selected_task_type
    
    # Configuration sp√©cifique selon le type de t√¢che
    if selected_task_type in ['classification', 'regression']:
        st.subheader("üéØ Variable Cible (Y)")
        
        # S√©lecteur de cible adapt√© au type de t√¢che
        if selected_task_type == 'classification':
            # Pour classification: privil√©gier les colonnes cat√©gorielles ou avec peu de valeurs uniques
            available_targets = [col for col in df.columns if df[col].nunique() <= 50 or not pd.api.types.is_numeric_dtype(df[col])]
        else:  # regression
            # Pour r√©gression: privil√©gier les colonnes num√©riques continues
            available_targets = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col]) and df[col].nunique() > 10]
        
        if not available_targets:
            st.error("‚ùå Aucune variable cible appropri√©e trouv√©e")
            if selected_task_type == 'classification':
                st.info("Pour la classification, la variable cible doit avoir un nombre limit√© de valeurs uniques (‚â§50)")
            else:
                st.info("Pour la r√©gression, la variable cible doit √™tre num√©rique avec plusieurs valeurs uniques")
        else:
            # Ajouter option "Aucune" en premier
            available_targets = [None] + available_targets
            
            if not st.session_state.target_column_for_ml_config or st.session_state.target_column_for_ml_config not in available_targets:
                target_idx = 0
            else:
                try:
                    target_idx = available_targets.index(st.session_state.target_column_for_ml_config)
                except ValueError:
                    target_idx = 0
            
            target_column = st.selectbox(
                "S√©lectionnez la variable √† pr√©dire",
                options=available_targets,
                index=target_idx,
                key="ml_target_selector_stable",
                help="Variable que le mod√®le apprendra √† pr√©dire"
            )
            
            # Mise √† jour de l'√©tat cible
            if target_column != st.session_state.target_column_for_ml_config:
                st.session_state.target_column_for_ml_config = target_column
                # Reset features si changement de cible
                st.session_state.feature_list_for_ml_config = []
            
            if target_column:
                # Analyse de la cible avec feedback utilisateur
                with st.spinner("üîç Analyse de la variable cible..."):
                    task_info = safe_get_task_type(df, target_column)
                
                if task_info["error"]:
                    st.error(f"‚ùå Erreur analyse cible: {task_info['error']}")
                else:
                    # Affichage des informations sur la t√¢che
                    if selected_task_type == "classification":
                        st.success(f"‚úÖ **T√¢che: CLASSIFICATION** ({task_info['n_classes']} classes d√©tect√©es)")
                        
                        # Affichage distribution des classes
                        class_dist = df[target_column].value_counts()
                        if len(class_dist) <= 10:
                            st.bar_chart(class_dist)
                            st.caption(f"Distribution des {len(class_dist)} classes")
                        
                        # V√©rification d√©s√©quilibre
                        try:
                            imbalance_info = detect_imbalance(df, target_column)
                            if imbalance_info and imbalance_info.get("is_imbalanced"):
                                st.warning(f"‚ö†Ô∏è **D√©s√©quilibre d√©tect√©** (ratio: {imbalance_info.get('imbalance_ratio', 'N/A'):.2f})")
                                st.info("üí° **Conseil**: Activez SMOTE dans l'√©tape de pr√©traitement pour am√©liorer les performances")
                        except Exception as e:
                            logger.debug(f"Imbalance detection failed: {e}")
                            
                    elif selected_task_type == "regression":
                        st.success("‚úÖ **T√¢che: R√âGRESSION**")
                        
                        # Statistiques de la variable cible
                        target_stats = df[target_column].describe()
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Moyenne", f"{target_stats['mean']:.3f}")
                        with col2:
                            st.metric("M√©diane", f"{target_stats['50%']:.3f}")
                        with col3:
                            st.metric("√âcart-type", f"{target_stats['std']:.3f}")
                        with col4:
                            st.metric("Plage", f"{target_stats['max'] - target_stats['min']:.3f}")
        
        # S√©lection des features avec validation
        st.subheader("üìä Variables Explicatives (X)")
        all_features = [col for col in df.columns if col != target_column] if target_column else list(df.columns)
        
        if all_features:
            # Features recommand√©es vs toutes
            recommend_features = st.checkbox(
                "S√©lection automatique des features pertinentes", 
                value=len(st.session_state.feature_list_for_ml_config) == 0,
                help="S√©lectionne automatiquement les variables les plus prometteuses"
            )
            
            if recommend_features and target_column:
                with st.spinner("ü§ñ Analyse des features..."):
                    try:
                        # S√©lection intelligente bas√©e sur les types
                        column_types = auto_detect_column_types(df)
                        recommended_features = []
                        
                        # Ajouter colonnes num√©riques (g√©n√©ralement bonnes pour ML)
                        recommended_features.extend(
                            col for col in column_types.get('numeric', []) 
                            if col != target_column and col in all_features
                        )
                        
                        # Ajouter quelques cat√©gorielles avec peu de modalit√©s
                        categorical_features = [
                            col for col in column_types.get('categorical', [])
                            if col != target_column and col in all_features and df[col].nunique() <= 20
                        ]
                        recommended_features.extend(categorical_features[:8])  # Limite √† 8
                        
                        if recommended_features:
                            st.session_state.feature_list_for_ml_config = recommended_features[:25]  # Limite globale
                            st.success(f"‚úÖ {len(st.session_state.feature_list_for_ml_config)} features s√©lectionn√©es automatiquement")
                        else:
                            st.session_state.feature_list_for_ml_config = all_features[:15]
                            st.info("‚ÑπÔ∏è S√©lection par d√©faut appliqu√©e")
                    except Exception as e:
                        logger.error(f"Auto feature selection failed: {e}")
                        st.session_state.feature_list_for_ml_config = all_features[:15]
            else:
                # S√©lection manuelle
                selected_features = st.multiselect(
                    "Variables d'entr√©e pour la pr√©diction",
                    options=all_features,
                    default=st.session_state.feature_list_for_ml_config if st.session_state.feature_list_for_ml_config else [],
                    key="ml_features_selector_stable",
                    help="Variables utilis√©es pour pr√©dire la cible"
                )
                st.session_state.feature_list_for_ml_config = selected_features
            
            # Affichage des features s√©lectionn√©es
            if st.session_state.feature_list_for_ml_config:
                st.success(f"‚úÖ {len(st.session_state.feature_list_for_ml_config)} features s√©lectionn√©es")
                if len(st.session_state.feature_list_for_ml_config) > 12:
                    features_display = st.session_state.feature_list_for_ml_config[:10]
                    st.caption(f"üìã {', '.join(features_display)} ... +{len(st.session_state.feature_list_for_ml_config)-10} autres")
                else:
                    st.caption(f"üìã {', '.join(st.session_state.feature_list_for_ml_config)}")
                
                # Avertissement si trop de features
                if len(st.session_state.feature_list_for_ml_config) > 30:
                    st.warning("‚ö†Ô∏è Nombre √©lev√© de features - risque de surapprentissage")
            else:
                st.warning("‚ö†Ô∏è Aucune feature s√©lectionn√©e")
        else:
            st.error("‚ùå Aucune feature disponible")
    
    else:  # Non supervis√© (Clustering)
        st.session_state.target_column_for_ml_config = None
        st.success("‚úÖ **T√¢che: CLUSTERING NON SUPERVIS√â**")
        st.info("üîç Le mod√®le identifiera automatiquement des groupes naturels dans les donn√©es sans variable cible")
        
        # S√©lection features pour clustering - uniquement num√©riques
        all_numeric_features = df.select_dtypes(include=['number']).columns.tolist()
        
        if not all_numeric_features:
            st.error("‚ùå Aucune variable num√©rique disponible pour le clustering")
            st.info("Le clustering n√©cessite des variables num√©riques. V√©rifiez les types de donn√©es de votre dataset.")
        else:
            st.subheader("üìä Variables pour le Clustering")
            st.info("üí° **Conseil**: S√©lectionnez des variables num√©riques repr√©sentatives pour obtenir de bons clusters")
            
            # S√©lection automatique pour clustering
            auto_cluster_features = st.checkbox(
                "S√©lection automatique des variables num√©riques",
                value=len(st.session_state.feature_list_for_ml_config) == 0,
                help="S√©lectionne toutes les variables num√©riques adapt√©es au clustering"
            )
            
            if auto_cluster_features:
                # NOUVEAU : Validation des features pour clustering
                validation_result = validate_clustering_features(df, all_numeric_features[:20])
                st.session_state.feature_list_for_ml_config = validation_result["valid_features"]
                
                if validation_result["warnings"]:
                    with st.expander("‚ö†Ô∏è Avertissements clustering", expanded=True):
                        for warning in validation_result["warnings"]:
                            st.warning(f"‚Ä¢ {warning}")
                
                st.success(f"‚úÖ {len(st.session_state.feature_list_for_ml_config)} variables num√©riques s√©lectionn√©es")
            else:
                # S√©lection manuelle
                clustering_features = st.multiselect(
                    "Variables pour l'analyse de clusters",
                    options=all_numeric_features,
                    default=st.session_state.feature_list_for_ml_config if st.session_state.feature_list_for_ml_config else all_numeric_features[:10],
                    key="clustering_features_selector",
                    help="Variables num√©riques utilis√©es pour identifier les patterns et clusters"
                )
                
                # Validation des features s√©lectionn√©es
                if clustering_features:
                    validation_result = validate_clustering_features(df, clustering_features)
                    st.session_state.feature_list_for_ml_config = validation_result["valid_features"]
                    
                    if validation_result["warnings"]:
                        with st.expander("‚ö†Ô∏è Avertissements clustering", expanded=True):
                            for warning in validation_result["warnings"]:
                                st.warning(f"‚Ä¢ {warning}")
                else:
                    st.session_state.feature_list_for_ml_config = clustering_features
            
            if st.session_state.feature_list_for_ml_config:
                st.success(f"‚úÖ {len(st.session_state.feature_list_for_ml_config)} variables s√©lectionn√©es pour le clustering")
                
                # V√©rification de la qualit√© des features pour clustering
                if len(st.session_state.feature_list_for_ml_config) < 2:
                    st.warning("‚ö†Ô∏è Au moins 2 variables sont recommand√©es pour un clustering significatif")
                elif len(st.session_state.feature_list_for_ml_config) > 15:
                    st.warning("‚ö†Ô∏è Nombre √©lev√© de variables - risque de 'mal√©diction de la dimensionnalit√©'")
                
                # Aper√ßu statistique
                with st.expander("üìà Aper√ßu des variables s√©lectionn√©es", expanded=False):
                    cluster_stats = df[st.session_state.feature_list_for_ml_config].describe()
                    st.dataframe(cluster_stats.style.format("{:.3f}"), use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Aucune variable s√©lectionn√©e pour le clustering")

# √âtape 2: Pr√©traitement
elif st.session_state.current_step == 2:
    st.header("üîß Configuration du Pr√©traitement")
    
    task_type = st.session_state.get('task_type', 'classification')
    
    st.info(f"""
    ‚ÑπÔ∏è **Pipeline de pr√©traitement pour {task_type.upper()}**: 
    Les transformations sont appliqu√©es dans l'ordre suivant, s√©par√©ment sur train/validation pour √©viter le data leakage.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üß© Gestion des Valeurs Manquantes")
        
        # Strat√©gies avec explications adapt√©es au type de t√¢che
        st.session_state.preprocessing_choices['numeric_imputation'] = st.selectbox(
            "Variables num√©riques",
            options=['mean', 'median', 'constant', 'knn'],
            index=['mean', 'median', 'constant', 'knn'].index(
                st.session_state.preprocessing_choices.get('numeric_imputation', 'mean')
            ),
            key='numeric_imputation_selector',
            help="mean=moyenne (robuste), median=m√©diane (extr√™mes), constant=0, knn=k-voisins (pr√©cis)"
        )
        
        st.session_state.preprocessing_choices['categorical_imputation'] = st.selectbox(
            "Variables cat√©gorielles",
            options=['most_frequent', 'constant'],
            index=['most_frequent', 'constant'].index(
                st.session_state.preprocessing_choices.get('categorical_imputation', 'most_frequent')
            ),
            key='categorical_imputation_selector',
            help="most_frequent=mode (fr√©quent), constant='missing' (explicite)"
        )
        
        st.subheader("üßπ Nettoyage Automatique")
        
        st.session_state.preprocessing_choices['remove_constant_cols'] = st.checkbox(
            "Supprimer colonnes constantes",
            value=st.session_state.preprocessing_choices.get('remove_constant_cols', True),
            key="remove_constant_checkbox",
            help="√âlimine variables sans variance (utile pour tous les types)"
        )
        
        st.session_state.preprocessing_choices['remove_identifier_cols'] = st.checkbox(
            "Supprimer colonnes identifiantes",
            value=st.session_state.preprocessing_choices.get('remove_identifier_cols', True),
            key="remove_id_checkbox",
            help="√âlimine variables avec valeurs uniques (ID, etc.)"
        )
    
    with col2:
        st.subheader("üìè Normalisation et Mise √† l'√©chelle")
        
        scale_help = {
            'classification': "Recommand√© pour SVM, KNN, r√©seaux de neurones",
            'regression': "Recommand√© pour la plupart des algorithmes", 
            'clustering': "ESSENTIEL pour le clustering (KMeans, DBSCAN)"
        }
        
        st.session_state.preprocessing_choices['scale_features'] = st.checkbox(
            "Normaliser les features",
            value=st.session_state.preprocessing_choices.get('scale_features', True),
            key="scale_features_checkbox",
            help=scale_help.get(task_type, "Recommand√© pour la plupart des algorithmes")
        )
        
        if task_type == 'clustering' and not st.session_state.preprocessing_choices.get('scale_features', True):
            st.error("‚ùå **ATTENTION**: La normalisation est CRITIQUE pour le clustering!")
            st.info("Les algorithmes comme KMeans sont sensibles √† l'√©chelle des variables")
        
        # Options sp√©cifiques au type de t√¢che
        if task_type == 'classification':
            st.subheader("‚öñÔ∏è Gestion du D√©s√©quilibre")
            
            if st.session_state.target_column_for_ml_config:
                try:
                    with st.spinner("Analyse du d√©s√©quilibre..."):
                        imbalance_info = detect_imbalance(df, st.session_state.target_column_for_ml_config)
                    
                    if imbalance_info and imbalance_info.get("is_imbalanced", False):
                        st.warning("üìâ **D√©s√©quilibre de classes d√©tect√©**")
                        ratio = imbalance_info.get('imbalance_ratio', 0)
                        majority_class = imbalance_info.get('majority_class', '')
                        minority_class = imbalance_info.get('minority_class', '')
                        
                        st.write(f"**Ratio**: {ratio:.2f}")
                        st.write(f"**Classe majoritaire**: {majority_class}")
                        st.write(f"**Classe minoritaire**: {minority_class}")
                        
                        st.session_state.preprocessing_choices['use_smote'] = st.checkbox(
                            "Activer SMOTE (Sur-√©chantillonnage)",
                            value=st.session_state.preprocessing_choices.get('use_smote', True),
                            key="smote_checkbox",
                            help="G√©n√®re des √©chantillons synth√©tiques pour √©quilibrer les classes minoritaires"
                        )
                        
                        if st.session_state.preprocessing_choices['use_smote']:
                            st.success("‚úÖ SMOTE activ√© - am√©liorera les performances sur les classes minoritaires")
                    else:
                        st.success("‚úÖ Classes √©quilibr√©es")
                        st.session_state.preprocessing_choices['use_smote'] = False
                        st.session_state.preprocessing_choices['use_smote'] = st.checkbox(
                            "Activer SMOTE (optionnel)",
                            value=False,
                            key="smote_optional_checkbox",
                            help="Peut √™tre activ√© m√™me si les classes sont √©quilibr√©es"
                        )
                        
                except Exception as e:
                    logger.error(f"Imbalance detection error: {e}")
                    st.warning("‚ö†Ô∏è Impossible d'analyser le d√©s√©quilibre")
                    st.session_state.preprocessing_choices['use_smote'] = False
            else:
                st.info("üîí Variable cible requise pour l'analyse de d√©s√©quilibre")
        
        elif task_type == 'clustering':
            st.subheader("üîç Options de Clustering")
            
            st.info("""
            **Recommandations pour le clustering:**
            - ‚úÖ Normalisation CRITIQUE
            - ‚úÖ Suppression des variables constantes
            - ‚úÖ Gestion des valeurs manquantes
            """)
            
            # Option sp√©cifique au clustering
            st.session_state.preprocessing_choices['pca_preprocessing'] = st.checkbox(
                "R√©duction de dimension (PCA optionnel)",
                value=st.session_state.preprocessing_choices.get('pca_preprocessing', False),
                help="R√©duit le bruit et amliore les performances sur donn√©es haute dimension"
            )

# √âtape 3: S√©lection des mod√®les
elif st.session_state.current_step == 3:
    st.header("ü§ñ S√©lection et Configuration des Mod√®les")
    
    task_type = st.session_state.get('task_type', 'classification')
    available_models = get_task_specific_models(task_type)
    
    if not available_models:
        st.error(f"‚ùå Aucun mod√®le disponible pour '{task_type}'")
        st.info("V√©rifiez la configuration du catalogue de mod√®les")
        st.stop()
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üéØ Mod√®les Disponibles")
        
        # Pr√©-s√©lection intelligente bas√©e sur le type de t√¢che
        if not st.session_state.selected_models_for_training:
            default_models = get_default_models_for_task(task_type)
            st.session_state.selected_models_for_training = default_models
        
        selected_models = st.multiselect(
            f"Mod√®les {task_type} √† entra√Æner et comparer",
            options=available_models,
            default=st.session_state.selected_models_for_training,
            key="models_multiselect_stable",
            help="Chaque mod√®le sera entra√Æn√© et √©valu√© automatiquement"
        )
        
        st.session_state.selected_models_for_training = selected_models
        
        # Informations d√©taill√©es sur les mod√®les
        if selected_models:
            st.success(f"‚úÖ {len(selected_models)} mod√®les s√©lectionn√©s")
            
            with st.expander("üìã D√©tails des mod√®les s√©lectionn√©s", expanded=False):
                for model_name in selected_models:
                    try:
                        model_config = MODEL_CATALOG[task_type][model_name]
                        st.write(f"**{model_name}**")
                        
                        if 'description' in model_config:
                            st.caption(f"‚Ä¢ {model_config['description']}")
                        
                        st.caption(f"‚Ä¢ Type: {type(model_config['model']).__name__}")
                        
                        if model_config.get('params'):
                            param_count = len(model_config['params'])
                            st.caption(f"‚Ä¢ Hyperparam√®tres: {param_count} disponibles")
                            
                        # Conseils sp√©cifiques
                        if task_type == 'clustering':
                            if model_name == 'KMeans':
                                st.caption("üí° **Conseil**: Excellent pour clusters sph√©riques de taille similaire")
                            elif model_name == 'DBSCAN':
                                st.caption("üí° **Conseil**: Robustes au bruit, trouve clusters de forme arbitraire")
                            elif model_name == 'GaussianMixture':
                                st.caption("üí° **Conseil**: Mod√®le probabiliste, bon pour clusters de taille variable")
                            
                    except Exception as e:
                        logger.error(f"Model info error for {model_name}: {e}")
                        st.caption(f"‚Ä¢ {model_name}: Informations non disponibles")
        else:
            st.warning("‚ö†Ô∏è Aucun mod√®le s√©lectionn√©")
    
    with col2:
        st.subheader("‚öôÔ∏è Configuration Avanc√©e")
        
        # Configuration diff√©rente selon le type de t√¢che
        if task_type != 'clustering':
            # Taille du jeu de test avec validation - UNIQUEMENT pour supervis√©
            test_split = st.slider(
                "Jeu de test (%)",
                min_value=10,
                max_value=40,
                value=st.session_state.get('test_split_for_ml_config', 20),
                step=5,
                key="test_split_slider_stable",
                help="Pourcentage de donn√©es r√©serv√©es pour l'√©valuation finale"
            )
            st.session_state.test_split_for_ml_config = test_split
            st.caption(f"üìä {test_split}% pour test, {100-test_split}% pour entra√Ænement")
        else:
            # Pour non supervis√©, pas de split
            st.info("üîç **Clustering**: Utilisation de 100% des donn√©es")
            st.session_state.test_split_for_ml_config = 0
            st.caption("Le clustering utilise tout le dataset pour trouver des patterns")
        
        # Optimisation des hyperparam√®tres
        optimize_hp = st.checkbox(
            "Optimisation hyperparam√®tres",
            value=st.session_state.get('optimize_hp_for_ml_config', False),
            key="optimize_hp_checkbox_stable",
            help="Recherche automatique des meilleurs param√®tres (plus long mais meilleures performances)"
        )
        st.session_state.optimize_hp_for_ml_config = optimize_hp
        
        if optimize_hp:
            st.warning("‚è∞ Temps d'entra√Ænement multipli√© par 3-5x")
            
            # Options d'optimisation adapt√©es
            if task_type == 'clustering':
                optimization_method = st.selectbox(
                    "M√©thode d'optimisation",
                    options=['Silhouette Score', 'Davies-Bouldin'],
                    index=0,
                    key="optimization_method_selector",
                    help="Silhouette=qualit√© clusters, Davies-Bouldin=compacit√©"
                )
            else:
                optimization_method = st.selectbox(
                    "M√©thode d'optimisation",
                    options=['GridSearch', 'RandomSearch'],
                    index=0,
                    key="optimization_method_selector",
                    help="GridSearch=exhaustif (pr√©cis), RandomSearch=√©chantillonnage (rapide)"
                )
            st.session_state.optimization_method = optimization_method
        
        # NOUVELLE ESTIMATION DU TEMPS plus pr√©cise
        n_features = len(st.session_state.feature_list_for_ml_config)
        use_smote = st.session_state.preprocessing_choices.get('use_smote', False)
        
        estimated_seconds = estimate_training_time(
            df, len(selected_models), task_type, optimize_hp, n_features, use_smote
        )
        
        estimated_minutes = max(1, estimated_seconds // 60)
        
        st.info(f"‚è±Ô∏è Temps estim√©: {estimated_minutes} minute(s)")
        
        # V√©rification des ressources syst√®me
        if selected_models:
            resource_check = check_system_resources(df, len(selected_models))
            
            if not resource_check["has_enough_resources"]:
                st.error("‚ùå Ressources syst√®me insuffisantes")
                for issue in resource_check["issues"]:
                    st.error(f"‚Ä¢ {issue}")
            elif resource_check["warnings"]:
                st.warning("‚ö†Ô∏è Ressources syst√®me limites")
                for warning in resource_check["warnings"]:
                    st.warning(f"‚Ä¢ {warning}")
        
        # Avertissements sp√©cifiques
        if task_type == 'clustering' and len(selected_models) > 3:
            st.warning("‚ö†Ô∏è Le clustering peut √™tre long avec beaucoup de donn√©es")

# √âtape 4: Lancement
elif st.session_state.current_step == 4:
    st.header("üöÄ Lancement de l'Exp√©rimentation")
    
    task_type = st.session_state.get('task_type', 'classification')
    
    # Validation compl√®te de la configuration
    config_issues = []
    config_warnings = []
    
    # V√©rifications obligatoires
    if task_type in ['classification', 'regression'] and not st.session_state.target_column_for_ml_config:
        config_issues.append("Variable cible non d√©finie")
    
    if not st.session_state.feature_list_for_ml_config:
        config_issues.append("Aucune variable explicative s√©lectionn√©e")
    elif len(st.session_state.feature_list_for_ml_config) < 2 and task_type == 'clustering':
        config_issues.append("Au moins 2 variables requises pour le clustering")
    
    if not st.session_state.selected_models_for_training:
        config_issues.append("Aucun mod√®le s√©lectionn√©")
    
    # V√©rifications de qualit√© sp√©cifiques
    if task_type == 'clustering':
        if not st.session_state.preprocessing_choices.get('scale_features', True):
            config_warnings.append("‚ö†Ô∏è La normalisation est CRITIQUE pour le clustering!")
        
        if len(st.session_state.feature_list_for_ml_config) > 15:
            config_warnings.append("Beaucoup de variables - risque de mal√©diction dimensionnelle")
    
    elif task_type == 'classification':
        if len(st.session_state.feature_list_for_ml_config) > 30:
            config_warnings.append("Beaucoup de features - risque de surapprentissage")
    
    if len(st.session_state.selected_models_for_training) > 5:
        config_warnings.append("Beaucoup de mod√®les s√©lectionn√©s (temps long)")
    
    # V√©rification finale des ressources
    resource_check = check_system_resources(df, len(st.session_state.selected_models_for_training))
    if not resource_check["has_enough_resources"]:
        config_issues.extend(resource_check["issues"])
    config_warnings.extend(resource_check["warnings"])
    
    # R√©capitulatif de configuration adapt√©
    with st.expander("üìã R√©capitulatif Configuration", expanded=True):
        if config_issues:
            st.error("‚ùå Configuration incompl√®te:")
            for issue in config_issues:
                st.write(f"‚Ä¢ {issue}")
        else:
            st.success("‚úÖ Configuration valide")
        
        if config_warnings:
            st.warning("‚ö†Ô∏è Avertissements:")
            for warning in config_warnings:
                st.write(f"‚Ä¢ {warning}")
        
        # D√©tails de la configuration adapt√©s au type de t√¢che
        if not config_issues:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**üìä Configuration Donn√©es**")
                st.write(f"‚Ä¢ Type: {task_type.upper()}")
                if task_type != 'clustering':
                    st.write(f"‚Ä¢ Cible: `{st.session_state.target_column_for_ml_config}`")
                st.write(f"‚Ä¢ Features: {len(st.session_state.feature_list_for_ml_config)}")
                if task_type != 'clustering':
                    st.write(f"‚Ä¢ Test: {st.session_state.test_split_for_ml_config}%")
                else:
                    st.write("‚Ä¢ Test: 0% (clustering)")
            
            with col2:
                st.markdown("**ü§ñ Configuration Mod√®les**")
                st.write(f"‚Ä¢ Mod√®les: {len(st.session_state.selected_models_for_training)}")
                st.write(f"‚Ä¢ Optimisation: {'‚úÖ' if st.session_state.optimize_hp_for_ml_config else '‚ùå'}")
                
                if task_type == 'classification':
                    st.write(f"‚Ä¢ SMOTE: {'‚úÖ' if st.session_state.preprocessing_choices.get('use_smote') else '‚ùå'}")
                
                st.write(f"‚Ä¢ Normalisation: {'‚úÖ' if st.session_state.preprocessing_choices.get('scale_features') else '‚ùå'}")
                
            # Informations ressources
            st.markdown("**üíª Ressources Syst√®me**")
            st.write(f"‚Ä¢ M√©moire disponible: {resource_check['available_memory_mb']:.0f} MB")
            st.write(f"‚Ä¢ M√©moire estim√©e n√©cessaire: {resource_check['estimated_needed_mb']:.0f} MB")
            st.write(f"‚Ä¢ Statut: {'‚úÖ Suffisante' if resource_check['has_enough_resources'] else '‚ùå Insuffisante'}")
    
    # Boutons d'action
    col_launch, col_reset, col_info = st.columns([2, 1, 2])
    
    with col_launch:
        launch_disabled = len(config_issues) > 0 or st.session_state.get('ml_training_in_progress', False)
        
        launch_button = st.button(
            "üöÄ Lancer l'Exp√©rimentation",
            type="primary",
            use_container_width=True,
            disabled=launch_disabled,
            help="D√©marrer l'entra√Ænement avec la configuration actuelle"
        )
        
        if launch_button:
            # Pr√©paration du lancement
            st.session_state.ml_training_in_progress = True
            st.session_state.ml_last_training_time = time.time()
            
            # Configuration finale adapt√©e au type de t√¢che
            training_config = {
                'df': df,
                'target_column': st.session_state.target_column_for_ml_config,
                'model_names': st.session_state.selected_models_for_training,
                'task_type': task_type,
                'test_size': st.session_state.test_split_for_ml_config / 100 if task_type != 'clustering' else 0.0,
                'optimize': st.session_state.optimize_hp_for_ml_config,
                'feature_list': st.session_state.feature_list_for_ml_config,
                'use_smote': st.session_state.preprocessing_choices.get('use_smote', False),
                'preprocessing_choices': st.session_state.preprocessing_choices
            }
            
            # NOUVEAU : Lancement avec progression d√©taill√©e
            progress_bar = st.progress(0)
            status_text = st.empty()
            results_container = st.empty()
            
            try:
                # √âtape 1: Pr√©paration
                status_text.text("üìä Pr√©paration des donn√©es...")
                progress_bar.progress(10)
                time.sleep(1)
                
                # √âtape 2: Entra√Ænement des mod√®les
                status_text.text("ü§ñ Entra√Ænement des mod√®les en cours...")
                
                # Appel principal avec progression
                n_models = len(st.session_state.selected_models_for_training)
                results = []
                
                for i, model_name in enumerate(st.session_state.selected_models_for_training):
                    status_text.text(f"üîß Entra√Ænement {i+1}/{n_models}: {model_name}")
                    progress_bar.progress(10 + int((i / n_models) * 80))
                    
                    # Entra√Ænement du mod√®le individuel
                    model_config = training_config.copy()
                    model_config['model_names'] = [model_name]
                    
                    try:
                        model_results = train_models(**model_config)
                        results.extend(model_results)
                    except Exception as e:
                        logger.error(f"Erreur entra√Ænement {model_name}: {e}")
                        results.append({
                            "model_name": model_name,
                            "metrics": {"error": str(e)},
                            "success": False
                        })
                    
                    time.sleep(0.5)  # Pause pour feedback utilisateur
                
                # √âtape 3: Finalisation
                status_text.text("‚úÖ Finalisation de l'exp√©rimentation...")
                progress_bar.progress(95)
                time.sleep(1)
                
                elapsed_time = time.time() - st.session_state.ml_last_training_time
                status_text.text(f"‚úÖ Exp√©rimentation termin√©e en {elapsed_time:.1f}s")
                progress_bar.progress(100)
                
                # Sauvegarde des r√©sultats
                st.session_state.ml_results = results
                st.session_state.ml_training_in_progress = False
                st.session_state.ml_error_count = 0
                
                # Analyse rapide des r√©sultats adapt√©e
                successful_models = [r for r in results if r.get('success', False) and not r.get('metrics', {}).get('error')]
                failed_models = [r for r in results if not r.get('success', False) or r.get('metrics', {}).get('error')]
                
                with results_container.container():
                    st.success(f"‚úÖ Exp√©rimentation termin√©e! {len(successful_models)}/{len(results)} mod√®les r√©ussis")
                    
                    if successful_models:
                        # Affichage du meilleur mod√®le adapt√©
                        if task_type == 'classification':
                            best_model = max(successful_models, key=lambda x: x.get('metrics', {}).get('accuracy', 0))
                            best_score = best_model.get('metrics', {}).get('accuracy', 0)
                            st.info(f"üèÜ Meilleur mod√®le: **{best_model['model_name']}** (Accuracy: {best_score:.3f})")
                        elif task_type == 'regression':
                            best_model = max(successful_models, key=lambda x: x.get('metrics', {}).get('r2', -999))
                            best_score = best_model.get('metrics', {}).get('r2', 0)
                            st.info(f"üèÜ Meilleur mod√®le: **{best_model['model_name']}** (R¬≤: {best_score:.3f})")
                        else:  # clustering
                            best_model = max(successful_models, key=lambda x: x.get('metrics', {}).get('silhouette_score', -999))
                            best_score = best_model.get('metrics', {}).get('silhouette_score', 0)
                            st.info(f"üèÜ Meilleur mod√®le: **{best_model['model_name']}** (Silhouette: {best_score:.3f})")
                    
                    if failed_models:
                        st.warning(f"‚ö†Ô∏è {len(failed_models)} mod√®les ont √©chou√©")
                    
                    # Navigation
                    st.balloons()
                    if st.button("üìà Voir les r√©sultats d√©taill√©s", use_container_width=True):
                        st.switch_page("pages/3_üìà_√âvaluation_du_Mod√®le.py")
                    
            except Exception as e:
                st.session_state.ml_training_in_progress = False
                st.session_state.ml_error_count = st.session_state.get('ml_error_count', 0) + 1
                
                error_msg = str(e)
                status_text.text("‚ùå Exp√©rimentation √©chou√©e")
                progress_bar.progress(0)
                
                st.error(f"‚ùå Erreur durant l'entra√Ænement: {error_msg[:200]}")
                logger.error(f"Training failed: {e}", exc_info=True)
    
    with col_reset:
        if st.button("üîÑ Reset Config", use_container_width=True, help="Remet √† z√©ro la configuration"):
            # Reset s√©lectif des param√®tres ML
            ml_keys_to_reset = [
                'target_column_for_ml_config',
                'feature_list_for_ml_config',
                'selected_models_for_training',
                'ml_results',
                'task_type',
                'previous_task_type'
            ]
            for key in ml_keys_to_reset:
                if key in st.session_state:
                    del st.session_state[key]
            
            st.session_state.current_step = 1
            st.success("Configuration r√©initialis√©e")
            st.rerun()
    
    with col_info:
        # √âtat actuel
        if st.session_state.get('ml_training_in_progress'):
            st.info("‚è≥ Entra√Ænement en cours...")
        elif st.session_state.get('ml_last_training_time'):
            last_time = time.strftime('%H:%M:%S', time.localtime(st.session_state.ml_last_training_time))
            st.caption(f"Dernier: {last_time}")
        
        if st.session_state.get('ml_error_count', 0) > 0:
            st.warning(f"‚ö†Ô∏è {st.session_state.ml_error_count} erreurs")

# Footer avec monitoring et navigation
st.markdown("---")
footer_col1, footer_col2, footer_col3, footer_col4 = st.columns(4)

with footer_col1:
    progress = (st.session_state.current_step / 4) * 100
    st.caption(f"üìä √âtape {st.session_state.current_step}/4 ({progress:.0f}%)")

with footer_col2:
    task_type_display = st.session_state.get('task_type', 'Non d√©fini')
    st.caption(f"üéØ {task_type_display.upper()}")

with footer_col3:
    try:
        sys_memory = psutil.virtual_memory().percent
        color = "üî¥" if sys_memory > 85 else "üü°" if sys_memory > 70 else "üü¢"
        st.caption(f"{color} RAM: {sys_memory:.0f}%")
    except:
        st.caption("üîß RAM: N/A")

with footer_col4:
    st.caption(f"‚è∞ {time.strftime('%H:%M:%S')}")

# Navigation entre les √©tapes
st.markdown("---")
nav_col1, nav_col2, nav_col3, nav_col4 = st.columns(4)

with nav_col1:
    if st.session_state.current_step > 1:
        if st.button("‚óÄÔ∏è √âtape pr√©c√©dente", use_container_width=True):
            st.session_state.current_step -= 1
            st.rerun()

with nav_col4:
    if st.session_state.current_step < 4:
        if st.button("√âtape suivante ‚ñ∂Ô∏è", use_container_width=True, type="primary"):
            # Validation avant passage √† l'√©tape suivante
            if st.session_state.current_step == 1:
                if st.session_state.task_type in ['classification', 'regression'] and not st.session_state.target_column_for_ml_config:
                    st.error("Veuillez s√©lectionner une variable cible")
                elif not st.session_state.feature_list_for_ml_config:
                    st.error("Veuillez s√©lectionner au moins une variable")
                else:
                    st.session_state.current_step += 1
                    st.rerun()
            else:
                st.session_state.current_step += 1
                st.rerun()

# Debug conditionnel
if os.getenv("DEBUG_MODE", "false").lower() == "true":
    with st.expander("üîç Debug ML Config", expanded=False):
        debug_info = {
            "current_step": st.session_state.current_step,
            "task_type": st.session_state.get('task_type'),
            "target_column": st.session_state.get('target_column_for_ml_config'),
            "num_features": len(st.session_state.get('feature_list_for_ml_config', [])),
            "num_models": len(st.session_state.get('selected_models_for_training', [])),
            "test_split": st.session_state.get('test_split_for_ml_config'),
            "training_in_progress": st.session_state.get('ml_training_in_progress', False),
            "error_count": st.session_state.get('ml_error_count', 0)
        }
        st.json(debug_info)