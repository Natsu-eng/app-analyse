import streamlit as st
import pandas as pd
import logging
import time
import psutil
import gc
from typing import Dict, List, Any, Optional
import os

# Imports des modules de l'application
from ml.catalog import MODEL_CATALOG
from utils.data_analysis import get_target_and_task, detect_imbalance, auto_detect_column_types
from ml.training import train_models
from utils.logging_config import get_logger

# Configuration
logger = get_logger(__name__)
st.set_page_config(page_title="Configuration ML", page_icon="‚öôÔ∏è", layout="wide")

# --- Configuration Production ---
def setup_ml_config_environment():
    """Configuration pour l'environnement de production ML"""
    if 'ml_config_setup_done' not in st.session_state:
        st.session_state.ml_config_setup_done = True
        
        # Masquer les √©l√©ments Streamlit en production
        if os.getenv('STREAMLIT_ENV') == 'production':
            hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            .stDeployButton {display:none;}
            footer {visibility: hidden;}
            #stDecoration {display:none;}
            </style>
            """
            st.markdown(hide_streamlit_style, unsafe_allow_html=True)

setup_ml_config_environment()

# --- V√©rification initiale des donn√©es ---
@st.cache_data(ttl=300)
def validate_dataframe_for_ml(df: pd.DataFrame) -> Dict[str, Any]:
    """Valide le DataFrame pour l'analyse ML"""
    validation = {
        "is_valid": True,
        "issues": [],
        "warnings": [],
        "min_rows_required": 50,
        "min_cols_required": 2
    }
    
    try:
        if df is None or df.empty:
            validation["is_valid"] = False
            validation["issues"].append("DataFrame vide ou non charg√©")
            return validation
            
        n_rows, n_cols = df.shape
        
        # V√©rification des dimensions minimales
        if n_rows < validation["min_rows_required"]:
            validation["is_valid"] = False
            validation["issues"].append(f"Trop peu de lignes ({n_rows} < {validation['min_rows_required']})")
            
        if n_cols < validation["min_cols_required"]:
            validation["is_valid"] = False
            validation["issues"].append(f"Trop peu de colonnes ({n_cols} < {validation['min_cols_required']})")
            
        # V√©rification des valeurs manquantes excessives
        missing_ratio = df.isnull().mean().max()
        if missing_ratio > 0.8:
            validation["warnings"].append(f"Certaines colonnes ont {missing_ratio:.1%} de valeurs manquantes")
            
        # V√©rification de la m√©moire
        try:
            memory_usage = df.memory_usage(deep=True).sum() / (1024**2)  # MB
            if memory_usage > 500:  # 500MB threshold
                validation["warnings"].append(f"Dataset volumineux ({memory_usage:.1f} MB)")
        except:
            validation["warnings"].append("Impossible de calculer l'utilisation m√©moire")
            
    except Exception as e:
        validation["is_valid"] = False
        validation["issues"].append(f"Erreur de validation: {str(e)}")
        logger.error(f"DataFrame validation error: {e}")
        
    return validation

# --- Initialisation de l'√©tat ML ---
def initialize_ml_config_state():
    """Initialise l'√©tat de configuration ML de fa√ßon robuste"""
    required_keys = {
        'target_column_for_ml_config': None,
        'feature_list_for_ml_config': [],
        'preprocessing_choices': {
            'numeric_imputation': 'mean',
            'categorical_imputation': 'most_frequent',
            'use_smote': False,
            'remove_constant_cols': True,
            'remove_identifier_cols': True
        },
        'selected_models_for_training': [],
        'test_split_for_ml_config': 20,
        'optimize_hp_for_ml_config': False,
        'task_type': 'classification',
        'ml_training_in_progress': False,
        'ml_last_training_time': None,
        'ml_error_count': 0
    }
    
    for key, default_value in required_keys.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

def safe_get_task_type(df: pd.DataFrame, target_column: str) -> Dict[str, Any]:
    """Version s√©curis√©e de la d√©tection du type de t√¢che avec dictionnaire"""
    try:
        if target_column not in df.columns:
            return {"task_type": "unknown", "n_classes": 0, "error": "Colonne cible non trouv√©e"}
            
        # get_target_and_task retourne un dictionnaire, pas un tuple
        result_dict = get_target_and_task(df, target_column)
        
        # Extraction des valeurs du dictionnaire
        task_type = result_dict.get("task", "unknown")
        target_type = result_dict.get("target_type", "unknown")
        
        # Calcul du nombre de classes si classification
        n_classes = 0
        if task_type == "classification" and target_column in df.columns:
            n_classes = df[target_column].nunique()
            
        return {
            "task_type": task_type, 
            "target_type": target_type,
            "n_classes": n_classes, 
            "error": None
        }
        
    except Exception as e:
        logger.error(f"Task type detection failed: {e}")
        return {"task_type": "unknown", "n_classes": 0, "error": str(e)}

# --- Interface Principale ---
st.title("‚öôÔ∏è Configuration D√©taill√©e de l'Exp√©rience ML")

# V√©rification initiale des donn√©es
if 'df' not in st.session_state or st.session_state.df is None:
    st.error("üìä Veuillez d'abord charger un jeu de donn√©es depuis la page d'Accueil.")
    st.page_link("app.py", label="üìã Retour √† l'accueil", icon="üè†")
    st.stop()

df = st.session_state.df

# Validation du DataFrame
validation_result = validate_dataframe_for_ml(df)
if not validation_result["is_valid"]:
    st.error("‚ùå Dataset incompatible avec l'analyse ML")
    for issue in validation_result["issues"]:
        st.write(f"‚Ä¢ {issue}")
    st.stop()

# Affichage des avertissements
if validation_result["warnings"]:
    with st.expander("‚ö†Ô∏è Avertissements", expanded=False):
        for warning in validation_result["warnings"]:
            st.warning(warning)

# Initialisation de l'√©tat
initialize_ml_config_state()

# M√©triques du dataset
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Lignes", f"{len(df):,}")
with col2:
    st.metric("Colonnes", f"{len(df.columns)}")
with col3:
    try:
        memory_mb = df.memory_usage(deep=True).sum() / (1024**2)
        st.metric("M√©moire", f"{memory_mb:.1f} MB")
    except:
        st.metric("M√©moire", "N/A")
with col4:
    st.metric("Type", "Pandas")

st.markdown("---")

# --- D√©finition des onglets ---
tab_target, tab_preprocess, tab_models, tab_launch = st.tabs([
    "üéØ 1. Cible & Features", 
    "üîß 2. Pr√©traitement", 
    "ü§ñ 3. S√©lection des Mod√®les", 
    "üöÄ 4. Lancement"
])

# --- Onglet 1: Cible & Features ---
with tab_target:
    st.header("üéØ D√©finition de la Cible et des Variables Explicatives")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Variable Cible (Y)")
        target_column = st.selectbox(
            "S√©lectionnez la variable √† pr√©dire", 
            options=df.columns,
            key="config_target_select",
            help="Cette variable sera utilis√©e comme cible pour l'apprentissage"
        )
        
        if target_column:
            task_info = safe_get_task_type(df, target_column)
            
            if task_info["error"]:
                st.error(f"Erreur de d√©tection: {task_info['error']}")
            else:
                # Affichage stylis√© du type de t√¢che
                task_type = task_info["task_type"]
                n_classes = task_info["n_classes"]
                
                if task_type == "classification":
                    st.success(f"**T√¢che d√©tect√©e : CLASSIFICATION**")
                    st.info(f"Nombre de classes : {n_classes}")
                    
                    # D√©tection du d√©s√©quilibre
                    imbalance_result = detect_imbalance(df, target_column)
                    if imbalance_result.get("is_imbalanced", False):
                        st.warning("‚öñÔ∏è **D√©s√©quilibre d√©tect√©** - Pensez √† activer SMOTE dans l'onglet Pr√©traitement")
                    
                elif task_type == "regression":
                    st.success(f"**T√¢che d√©tect√©e : R√âGRESSION**")
                    # Statistiques de la variable cible
                    target_stats = df[target_column].describe()
                    st.write(f"**Plage de valeurs :** {target_stats['min']:.2f} √† {target_stats['max']:.2f}")
                    
                elif task_type == "unsupervised":
                    st.info("**T√¢che d√©tect√©e : NON SUPERVIS√â**")
                    st.caption("Clustering ou r√©duction de dimension")
                
                st.session_state.task_type = task_type
                st.session_state.target_column_for_ml_config = target_column
    
    with col2:
        if st.session_state.target_column_for_ml_config:
            st.subheader("Variables Explicatives (X)")
            
            all_features = [col for col in df.columns if col != st.session_state.target_column_for_ml_config]
            
            # D√©tection automatique des types de colonnes pour le guide
            with st.spinner("Analyse des variables..."):
                column_types = auto_detect_column_types(df[all_features])
            
            # Interface de s√©lection avec informations
            selected_features = st.multiselect(
                "S√©lectionnez les variables d'entr√©e",
                options=all_features,
                default=all_features,
                key="config_features_select",
                help="Variables utilis√©es pour pr√©dire la cible"
            )
            
            st.session_state.feature_list_for_ml_config = selected_features
            
            # Statistiques des features s√©lectionn√©es
            if selected_features:
                st.success(f"‚úÖ {len(selected_features)} variables s√©lectionn√©es")
                
                # R√©partition par type
                numeric_count = len([f for f in selected_features if f in column_types.get('numeric', [])])
                categorical_count = len([f for f in selected_features if f in column_types.get('categorical', [])])
                other_count = len(selected_features) - numeric_count - categorical_count
                
                st.caption(f"üìä {numeric_count} num√©riques ‚Ä¢ {categorical_count} cat√©gorielles ‚Ä¢ {other_count} autres")
            else:
                st.error("‚ùå Aucune variable s√©lectionn√©e")

# --- Onglet 2: Pr√©traitement ---
with tab_preprocess:
    st.header("üîß Options de Pr√©traitement des Donn√©es")
    
    st.info("""
    ‚ö†Ô∏è **Important** : Ces traitements sont appliqu√©s √† l'int√©rieur de la validation crois√©e 
    pour √©viter les fuites de donn√©es (data leakage). Chaque fold est trait√© ind√©pendamment.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üß© Gestion des valeurs manquantes")
        
        st.session_state.preprocessing_choices['numeric_imputation'] = st.selectbox(
            "Strat√©gie pour les variables num√©riques",
            options=['mean', 'median', 'constant', 'knn'],
            index=0,
            key='cfg_num_strat',
            help="Moyenne, M√©diane, Valeur constante (0), ou K-plus proches voisins"
        )
        
        st.session_state.preprocessing_choices['categorical_imputation'] = st.selectbox(
            "Strat√©gie pour les variables cat√©gorielles",
            options=['most_frequent', 'constant'],
            index=0,
            key='cfg_cat_strat',
            help="Valeur la plus fr√©quente ou valeur constante ('missing')"
        )
        
        st.session_state.preprocessing_choices['remove_constant_cols'] = st.checkbox(
            "Supprimer les colonnes constantes",
            value=True,
            key="cfg_remove_constant",
            help="√âlimine les colonnes sans variance"
        )
        
        st.session_state.preprocessing_choices['remove_identifier_cols'] = st.checkbox(
            "Supprimer les colonnes de type ID",
            value=True,
            key="cfg_remove_id",
            help="√âlimine les colonnes avec des valeurs uniques pour chaque ligne"
        )
    
    with col2:
        st.subheader("‚öñÔ∏è √âquilibrage des donn√©es")
        
        # Afficher SMOTE seulement pour la classification
        if st.session_state.get('task_type') == 'classification':
            imbalance_info = detect_imbalance(df, st.session_state.target_column_for_ml_config)
            
            if imbalance_info.get("is_imbalanced", False):
                st.warning("üìâ **D√©s√©quilibre d√©tect√©**")
                st.write(f"Ratio de d√©s√©quilibre : {imbalance_info.get('imbalance_ratio', 'N/A'):.2f}")
                
                st.session_state.preprocessing_choices['use_smote'] = st.checkbox(
                    "Activer SMOTE (Synthetic Minority Over-sampling Technique)",
                    value=True,
                    key="cfg_smote",
                    help="G√©n√®re des √©chantillons synth√©tiques pour les classes minoritaires"
                )
                
                if st.session_state.preprocessing_choices['use_smote']:
                    st.success("‚úÖ SMOTE sera appliqu√© pendant l'entra√Ænement")
            else:
                st.success("‚úÖ Les classes sont √©quilibr√©es")
                st.session_state.preprocessing_choices['use_smote'] = False
        else:
            st.info("üîí L'√©quilibrage SMOTE n'est disponible que pour la classification")
            st.session_state.preprocessing_choices['use_smote'] = False

# --- Onglet 3: S√©lection des Mod√®les ---
with tab_models:
    st.header("ü§ñ S√©lection et Configuration des Mod√®les")
    
    task_type = st.session_state.get('task_type', 'classification')
    available_models = list(MODEL_CATALOG.get(task_type, {}).keys())
    
    if not available_models:
        st.error(f"‚ùå Aucun mod√®le disponible pour la t√¢che '{task_type}'")
        st.stop()
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Mod√®les disponibles")
        
        selected_models = st.multiselect(
            "S√©lectionnez les mod√®les √† entra√Æner et comparer",
            options=available_models,
            default=available_models[:2] if len(available_models) >= 2 else available_models,
            key="cfg_model_select",
            help="Les mod√®les seront entra√Æn√©s et compar√©s automatiquement"
        )
        
        st.session_state.selected_models_for_training = selected_models
        
        # Informations sur les mod√®les s√©lectionn√©s
        if selected_models:
            st.success(f"‚úÖ {len(selected_models)} mod√®les s√©lectionn√©s")
            
            # Afficher les d√©tails des mod√®les
            with st.expander("üìã D√©tails des mod√®les s√©lectionn√©s", expanded=False):
                for model_name in selected_models:
                    model_config = MODEL_CATALOG[task_type][model_name]
                    st.write(f"**{model_name}**")
                    st.caption(f"Type: {type(model_config['model']).__name__}")
                    if model_config.get('params'):
                        st.caption(f"Hyperparam√®tres √† optimiser: {len(model_config['params'])}")
    
    with col2:
        st.subheader("‚öôÔ∏è Configuration")
        
        st.session_state.test_split_for_ml_config = st.slider(
            "Taille du jeu de test (%)", 
            min_value=10, 
            max_value=40, 
            value=20, 
            step=5,
            key="cfg_test_size",
            help="Pourcentage des donn√©es r√©serv√© pour le test"
        )
        
        st.session_state.optimize_hp_for_ml_config = st.checkbox(
            "Optimisation des hyperparam√®tres", 
            value=False,
            key="cfg_optimize",
            help="Recherche syst√©matique des meilleurs param√®tres (plus long)"
        )
        
        if st.session_state.optimize_hp_for_ml_config:
            st.warning("‚è∞ L'optimisation peut multiplier le temps d'entra√Ænement")

# --- Onglet 4: Lancement ---
with tab_launch:
    st.header("üöÄ Lancement de l'Exp√©rimentation")
    
    # V√©rification de la configuration
    config_errors = []
    
    if not st.session_state.target_column_for_ml_config:
        config_errors.append("Variable cible non d√©finie")
    
    if not st.session_state.feature_list_for_ml_config:
        config_errors.append("Aucune variable explicative s√©lectionn√©e")
    
    if not st.session_state.selected_models_for_training:
        config_errors.append("Aucun mod√®le s√©lectionn√©")
    
    # Affichage du r√©capitulatif
    with st.expander("üìã R√©capitulatif de la Configuration", expanded=True):
        if config_errors:
            st.error("‚ùå Configuration incompl√®te:")
            for error in config_errors:
                st.write(f"‚Ä¢ {error}")
        else:
            st.success("‚úÖ Configuration valide")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Donn√©es**")
                st.write(f"‚Ä¢ Cible: `{st.session_state.target_column_for_ml_config}`")
                st.write(f"‚Ä¢ Features: {len(st.session_state.feature_list_for_ml_config)} variables")
                st.write(f"‚Ä¢ Test: {st.session_state.test_split_for_ml_config}%")
                
            with col2:
                st.write("**Mod√®les**")
                st.write(f"‚Ä¢ {len(st.session_state.selected_models_for_training)} mod√®les")
                st.write(f"‚Ä¢ Optimisation: {'‚úÖ' if st.session_state.optimize_hp_for_ml_config else '‚ùå'}")
                st.write(f"‚Ä¢ SMOTE: {'‚úÖ' if st.session_state.preprocessing_choices.get('use_smote') else '‚ùå'}")
    
    # Bouton de lancement
    col_btn, col_info = st.columns([1, 2])
    
    with col_btn:
        launch_disabled = len(config_errors) > 0 or st.session_state.get('ml_training_in_progress', False)
        
        if st.button(
            "üöÄ Lancer l'Exp√©rimentation", 
            type="primary", 
            use_container_width=True,
            disabled=launch_disabled,
            help="D√©marrer l'entra√Ænement des mod√®les"
        ):
            st.session_state.ml_training_in_progress = True
            st.session_state.ml_last_training_time = time.time()
            
            # Lancement de l'entra√Ænement
            with st.spinner("üß† Entra√Ænement des mod√®les en cours... Cette op√©ration peut prendre plusieurs minutes."):
                try:
                    results = train_models(
                        df=st.session_state.df,
                        target_column=st.session_state.target_column_for_ml_config,
                        model_names=st.session_state.selected_models_for_training,
                        task_type=st.session_state.task_type,
                        test_size=st.session_state.test_split_for_ml_config / 100,
                        optimize=st.session_state.optimize_hp_for_ml_config,
                        feature_list=st.session_state.feature_list_for_ml_config,
                        use_smote=st.session_state.preprocessing_choices.get('use_smote', False),
                        preprocessing_choices=st.session_state.preprocessing_choices
                    )
                    
                    st.session_state.ml_results = results
                    st.session_state.ml_training_in_progress = False
                    st.session_state.ml_error_count = 0
                    
                    st.success("‚úÖ Exp√©rimentation termin√©e avec succ√®s!")
                    st.balloons()
                    
                    # Affichage des r√©sultats
                    st.subheader("üìä R√©sultats de l'Exp√©rimentation")
                    
                    successful_models = 0
                    for res in results:
                        if res['metrics'].get('error'):
                            st.error(f"**{res['model_name']}**: ‚ùå √âchec - {res['metrics']['error']}")
                        else:
                            successful_models += 1
                            # Score principal selon le type de t√¢che
                            if st.session_state.task_type == "classification":
                                score = res['metrics'].get('accuracy', 0)
                                st.success(f"**{res['model_name']}**: ‚úÖ Exactitude = {score:.3f}")
                            elif st.session_state.task_type == "regression":
                                score = res['metrics'].get('r2', 0)
                                st.success(f"**{res['model_name']}**: ‚úÖ R¬≤ = {score:.3f}")
                            else:
                                score = res['metrics'].get('silhouette_score', 0)
                                st.success(f"**{res['model_name']}**: ‚úÖ Score = {score:.3f}")
                    
                    st.info(f"üìà {successful_models}/{len(results)} mod√®les entra√Æn√©s avec succ√®s")
                    
                    # Navigation vers les r√©sultats
                    st.page_link("pages/4_üìà_√âvaluation_du_Mod√®le.py", label="üìä Voir les r√©sultats d√©taill√©s", icon="üìà")
                    
                except Exception as e:
                    st.session_state.ml_training_in_progress = False
                    st.session_state.ml_error_count += 1
                    st.error(f"‚ùå Erreur lors de l'entra√Ænement: {str(e)}")
                    logger.error(f"Training failed: {e}", exc_info=True)
    
    with col_info:
        if st.session_state.get('ml_training_in_progress', False):
            st.info("‚è≥ Entra√Ænement en cours... Veuillez patienter.")
        elif st.session_state.get('ml_last_training_time'):
            last_time = st.session_state.ml_last_training_time
            st.caption(f"Dernier entra√Ænement: {time.strftime('%H:%M:%S', time.localtime(last_time))}")
        
        if st.session_state.get('ml_error_count', 0) > 0:
            st.warning(f"‚ö†Ô∏è {st.session_state.ml_error_count} erreur(s) lors des entra√Ænements")

# Footer avec monitoring
st.markdown("---")
footer_col1, footer_col2, footer_col3 = st.columns(3)

with footer_col1:
    if st.session_state.get('ml_error_count', 0) > 0:
        st.caption(f"‚ö†Ô∏è Erreurs ML: {st.session_state.ml_error_count}")

with footer_col2:
    current_time = time.strftime("%H:%M:%S")
    st.caption(f"‚è∞ Session: {current_time}")

with footer_col3:
    if st.button("üßπ Nettoyer cache ML", help="Lib√®re la m√©moire des mod√®les"):
        gc.collect()
        if 'ml_results' in st.session_state:
            del st.session_state.ml_results
        st.success("Cache ML nettoy√©")
        st.rerun()

# Gestion d'erreurs globale
if st.session_state.get('ml_error_count', 0) > 5:
    st.error("‚ö†Ô∏è Plusieurs erreurs d√©tect√©es. Consid√©rez recharger l'application.")
    if st.button("üîÑ Recharger la page ML"):
        st.session_state.ml_error_count = 0
        st.rerun()

# Ajoutez cette fonction dans votre Configuration_ML.py
def clear_cache_and_restart():
    """Nettoie le cache et red√©marre l'application"""
    try:
        st.cache_data.clear()
        st.success("Cache nettoy√© avec succ√®s!")
        st.rerun()
    except Exception as e:
        st.error(f"Erreur lors du nettoyage du cache : {e}")

# Bouton de nettoyage dans la sidebar
if st.sidebar.button("üîÑ Nettoyer le cache"):
    clear_cache_and_restart()