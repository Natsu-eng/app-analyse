import streamlit as st
import pandas as pd
from typing import Dict, List

# Imports des modules de l'application
from ml.catalog import MODEL_CATALOG
from utils.data_analysis import get_task_type, detect_imbalance
from ml.training import train_models # NOUVEL IMPORT

st.set_page_config(page_title="Configuration ML", page_icon="‚öôÔ∏è", layout="wide")

st.title("‚öôÔ∏è Configuration D√©taill√©e de l'Exp√©rience ML")

# --- V√©rification initiale des donn√©es ---
if 'df' not in st.session_state or st.session_state.df is None:
    st.warning("Veuillez d'abord charger un jeu de donn√©es depuis la page d'Accueil.")
    st.stop()

df = st.session_state.df

# Initialisation de l'√©tat de session pour cette page
def init_ml_config_state():
    if 'target_column_for_ml_config' not in st.session_state:
        st.session_state.target_column_for_ml_config = None
    if 'feature_list_for_ml_config' not in st.session_state:
        st.session_state.feature_list_for_ml_config = list(df.columns)
    if 'preprocessing_choices' not in st.session_state:
        st.session_state.preprocessing_choices = {}
    if 'selected_models_for_training' not in st.session_state:
        st.session_state.selected_models_for_training = []
    if 'test_split_for_ml_config' not in st.session_state:
        st.session_state.test_split_for_ml_config = 20
    if 'optimize_hp_for_ml_config' not in st.session_state:
        st.session_state.optimize_hp_for_ml_config = False

init_ml_config_state()

# --- D√©finition des onglets ---
tab_target, tab_preprocess, tab_models, tab_launch = st.tabs([
    "1. Cible & Features", 
    "2. Pr√©traitement", 
    "3. S√©lection des Mod√®les", 
    "üöÄ 4. Lancement"
])

# --- Onglet 1: Cible & Features ---
with tab_target:
    st.header("D√©finition de la Cible et des Variables Explicatives")
    col1, col2 = st.columns(2)
    with col1:
        st.session_state.target_column_for_ml_config = st.selectbox(
            "Variable Cible (Y)", 
            options=df.columns,
            key="config_target_select"
        )
        if st.session_state.target_column_for_ml_config:
            task_type, n_classes = get_task_type(df[st.session_state.target_column_for_ml_config])
            st.session_state.task_type = task_type # Sauvegarde pour les autres onglets
            st.info(f"T√¢che d√©tect√©e : **{task_type.upper()}**")
    
    with col2:
        if st.session_state.target_column_for_ml_config:
            all_features = [col for col in df.columns if col != st.session_state.target_column_for_ml_config]
            st.session_state.feature_list_for_ml_config = st.multiselect(
                "Variables Explicatives (X)",
                options=all_features,
                default=all_features,
                key="config_features_select"
            )

# --- Onglet 2: Pr√©traitement ---
with tab_preprocess:
    st.header("Options de Pr√©traitement des Donn√©es")
    st.info("Ces √©tapes seront appliqu√©es √† l'int√©rieur de la validation crois√©e pour √©viter les fuites de donn√©es.")
    
    choices = st.session_state.preprocessing_choices
    
    # Imputation
    st.subheader("Gestion des valeurs manquantes")
    choices['numeric_imputation'] = st.selectbox("Strat√©gie num√©rique", ['mean', 'median', 'knn'], key='cfg_num_strat')
    choices['categorical_imputation'] = st.selectbox("Strat√©gie cat√©gorielle", ['most_frequent', 'constant'], key='cfg_cat_strat')

    # √âquilibrage (si classification)
    if st.session_state.get('task_type') == 'classification':
        st.subheader("√âquilibrage des classes")
        if detect_imbalance(df, st.session_state.target_column_for_ml_config):
            st.warning("Un d√©s√©quilibre a √©t√© d√©tect√© dans la variable cible.")
        choices['use_smote'] = st.checkbox("Activer SMOTE pour r√©-√©chantillonner", key="cfg_smote")

# --- Onglet 3: S√©lection des Mod√®les ---
with tab_models:
    st.header("S√©lection et Configuration des Mod√®les")
    task_type = st.session_state.get('task_type', 'classification')
    
    st.session_state.selected_models_for_training = st.multiselect(
        "Mod√®les √† entra√Æner et comparer",
        options=list(MODEL_CATALOG.get(task_type, {}).keys()),
        key="cfg_model_select"
    )
    
    st.subheader("Configuration de l'entra√Ænement")
    st.session_state.test_split_for_ml_config = st.slider("Taille du jeu de test (%)", 10, 50, 20, 5, key="cfg_test_size")
    st.session_state.optimize_hp_for_ml_config = st.checkbox("Optimiser les hyperparam√®tres (GridSearch - plus long)", key="cfg_optimize")

# --- Onglet 4: Lancement ---
with tab_launch:
    st.header("Lancer l'Exp√©rimentation")
    
    with st.expander("R√©capitulatif de la Configuration", expanded=True):
        st.write(f"- **Cible**: `{st.session_state.target_column_for_ml_config}`")
        st.write(f"- **Features**: {len(st.session_state.feature_list_for_ml_config)} s√©lectionn√©es")
        st.write(f"- **Mod√®les**: `{st.session_state.selected_models_for_training}`")
        st.write(f"- **Pr√©traitement**: Imputation num: `{choices.get('numeric_imputation')}`, cat: `{choices.get('categorical_imputation')}`, SMOTE: `{choices.get('use_smote')}`")
        st.write(f"- **Optimisation HP**: `{st.session_state.optimize_hp_for_ml_config}`")

    if st.button("üöÄ Lancer l'Exp√©rimentation", type="primary", use_container_width=True):
        if not st.session_state.target_column_for_ml_config or not st.session_state.feature_list_for_ml_config or not st.session_state.selected_models_for_training:
            st.error("Configuration incompl√®te. Veuillez v√©rifier les onglets pr√©c√©dents.")
        else:
            with st.spinner("L'exp√©rimentation est en cours... Veuillez patienter."):
                # APPEL √Ä LA NOUVELLE FONCTION CENTRALIS√âE
                results = train_models(
                    df=st.session_state.df,
                    target_column=st.session_state.target_column_for_ml_config,
                    model_names=st.session_state.selected_models_for_training,
                    task_type=st.session_state.task_type,
                    test_size=st.session_state.test_split_for_ml_config / 100,
                    optimize=st.session_state.optimize_hp_for_ml_config,
                    feature_list=st.session_state.feature_list_for_ml_config,
                    use_smote=st.session_state.preprocessing_choices.get('use_smote', False),
                    preprocessing_choices=st.session_state.preprocessing_choices
                )
            
            st.session_state.ml_results = results
            st.success("Exp√©rimentation termin√©e !")
            st.balloons()

            # Afficher un r√©sum√© des r√©sultats
            st.subheader("R√©sultats de l'Exp√©rimentation")
            for res in results:
                if res['metrics'].get('error'):
                    st.error(f"**{res['model_name']}**: √âchec - {res['metrics']['error']}")
                else:
                    score = res['metrics'].get('accuracy') or res['metrics'].get('r2') or res['metrics'].get('silhouette_score', 0)
                    st.success(f"**{res['model_name']}**: Termin√© avec un score de {score:.3f}")
            
            st.info("Vous pouvez maintenant consulter les r√©sultats d√©taill√©s dans la page '√âvaluation du Mod√®le'.")